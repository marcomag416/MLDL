{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f9837e-8426-4862-92a7-a81333871466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import sys\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8868c13-576f-4ea9-81e3-859cc15adee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (0.16.6)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (1.45.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (65.5.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\luca\\pycharmprojects\\mldl\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: luca-porta (porta-luca). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#install and import wandb for data collecting\n",
    "!pip install wandb\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15e1d8c-98ce-4c48-b1c7-2a97f3da2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and extraction complete!\n"
     ]
    }
   ],
   "source": [
    "#download and extract project repository\n",
    "\n",
    "url= \"https://github.com/marcomag416/MLDL/archive/refs/heads/main.zip\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    #print(response.content)\n",
    "    # Open the downloaded bytes and extract them\n",
    "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
    "        zip_file.extractall('./')\n",
    "    print('Download and extraction complete!')\n",
    "\n",
    "sys.path.insert(0, './MLDL-main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2435c848-d27e-45bc-978b-9b59603b8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cityscape_dataset_path = \"./dataset/Cityscapes/Cityspaces\"\n",
    "# Define paths\n",
    "gta_dataset_path = \"./dataset/\"\n",
    "images_path = gta_dataset_path + 'GTA5/images'\n",
    "labels_path = gta_dataset_path + 'GTA5/labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60b765d-cdce-47fa-af57-bf645b3e456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to hold data\n",
    "data = []\n",
    "\n",
    "# Load images and corresponding masks\n",
    "for image_filename in os.listdir(images_path):\n",
    "    if image_filename.endswith('.png'):\n",
    "        image_path = os.path.join(images_path, image_filename)\n",
    "        mask_path = os.path.join(labels_path, image_filename)\n",
    "\n",
    "        # Check if corresponding mask file exists\n",
    "        if os.path.exists(mask_path):\n",
    "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                mask = Image.open(mask_path)\n",
    "\n",
    "                # Add data to list\n",
    "                data.append({\n",
    "                    'image_path': image_path,\n",
    "                    'mask_path': mask_path\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('./gta5_segmentation_dataset.csv', index=False)\n",
    "\n",
    "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b57d8b-e457-43c3-8b80-e4a644fbd93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.10 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "#import from packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "from timeit import default_timer as timer\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#other imports\n",
    "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from models.domainAdaptationModule import DomainAdaptationModule\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10f8a0b-3ed9-45a6-9a35-dbed06440cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
    "\n",
    "if __name__ != '__main__':\n",
    "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the custom dataset class\n",
    "class GTASegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_mapping = self._create_label_mapping()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        mask_name = self.data_frame.iloc[idx, 1]\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "\n",
    "        mask = self._map_mask(np.array(mask))\n",
    "\n",
    "        if self.transform:\n",
    "            # Convert mask to tensor without normalization\n",
    "            mask = torch.from_numpy(mask).permute(2, 0, 1).float()\n",
    "            mask = mask[0]\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
    "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
    "        return label_mapping\n",
    "\n",
    "    def _map_mask(self, mask):\n",
    "        new_mask = np.zeros_like(mask)\n",
    "        for color, label_id in self.label_mapping.items():\n",
    "            color_mask = np.all(mask == color, axis=-1)\n",
    "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
    "        return new_mask\n",
    "\n",
    "\n",
    "\n",
    "# Define paths\n",
    "csv_file = './gta5_segmentation_dataset.csv'\n",
    "\n",
    "# Define image transformations\n",
    "transform = A.Compose([\n",
    "    A.Resize(720, 1280),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.OneOf([\n",
    "        A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
    "        A.NoOp()\n",
    "    ], p=0.5),\n",
    "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67be94fd-3ab5-4f45-aa66-0804b6b3c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_Dataset size: 500\n"
     ]
    }
   ],
   "source": [
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "        self.label_type = label_type\n",
    "\n",
    "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
    "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "\n",
    "        # Manually iterate over directories\n",
    "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
    "        for city in cities:\n",
    "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
    "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
    "\n",
    "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
    "                continue\n",
    "\n",
    "            for img_file in os.listdir(img_dir_city):\n",
    "                if img_file.endswith('_leftImg8bit.png'):\n",
    "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
    "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
    "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
    "\n",
    "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.label_paths.append(lbl_path)\n",
    "                    else:\n",
    "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        lbl_path = self.label_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = Image.open(lbl_path)\n",
    "\n",
    "        image = np.array(image)\n",
    "        label = np.array(label)\n",
    "\n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=label)\n",
    "            image, label = augmented['image'], augmented['mask']\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_transforms = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_dataset = Cityscapes(root_dir=cityscape_dataset_path, split='val', transforms=image_transforms)\n",
    "\n",
    "\n",
    "print(f\"Val_Dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9344705c-1c77-4586-8f8e-e1d504b72881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
    "        inputs_train = inputs_train.to(device)\n",
    "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
    "\n",
    "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
    "        outputs_train, _, _ = model(inputs_train)  # Forward pass\n",
    "        # print( \"train\")\n",
    "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
    "\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer_train.step()  # Update the weights\n",
    "\n",
    "        wandb.log({\"train/Batch loss\": loss})\n",
    "\n",
    "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
    "        _, predicted_train = outputs_train.max(1)\n",
    "        total += targets_train.size(0)\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = train_loss / total\n",
    "\n",
    "    wandb.log({\"train/Epoch loss\": avg_loss})\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds[target_inds]).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "\n",
    "    return np.array(ious)\n",
    "\n",
    "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    all_ious = []  # List to store IoUs for each batch\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation during inference\n",
    "        for inputs_test, targets_test in dataloader:\n",
    "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_test = model(inputs_test)  # Forward pass\n",
    "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
    "\n",
    "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
    "            _, predicted_test = outputs_test.max(1)\n",
    "            total += targets_test.size(0)\n",
    "\n",
    "            # Compute IoU for this batch\n",
    "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
    "            all_ious.append(batch_ious)\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = test_loss / total\n",
    "\n",
    "    wandb.log({})\n",
    "\n",
    "    # Calculate mean IoU\n",
    "    all_ious = np.array(all_ious)\n",
    "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
    "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
    "\n",
    "    wandb.log({\"val/Validation loss\": avg_loss, \"val/mIoU\": miou})\n",
    "\n",
    "    return avg_loss, miou, mean_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f4800c-7427-44a6-a9b4-d421708800c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_bisenet import BiSeNet\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "\n",
    "\n",
    "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "context_path = 'resnet18'\n",
    "\n",
    "#save hyperparameters\n",
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"max_epochs\": 50,\n",
    "    \"batch_size\": 8,\n",
    "    \"weight_decay\": \"None\",\n",
    "    \"dataset\": \"Cityscapes\",\n",
    "    \"scheduler\": \"None\",\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"transformations\": \"gaussian blur, horizontal flip\"\n",
    "}\n",
    "\n",
    "\n",
    "# create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "#scheduler = PolynomialLR(optimizer, total_iters=config[\"max_epochs\"], power=config[\"polyPower\"])\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4978301-3e15-4105-a835-71afb54c5691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Luca\\PycharmProjects\\MLDL\\Project\\testingMIOU\\wandb\\run-20240702_145946-s0191cua</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter/runs/s0191cua' target=\"_blank\">horizFlip_rc_jitter</a></strong> to <a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter' target=\"_blank\">https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter/runs/s0191cua' target=\"_blank\">https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter/runs/s0191cua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.3908826417922973, mIoU: 13.04%\n",
      "Class: 0, mIoU: 0.4380\n",
      "Class: 1, mIoU: 0.0106\n",
      "Class: 2, mIoU: 0.4449\n",
      "Class: 3, mIoU: 0.0233\n",
      "Class: 4, mIoU: 0.0002\n",
      "Class: 5, mIoU: 0.0223\n",
      "Class: 6, mIoU: 0.0010\n",
      "Class: 7, mIoU: 0.0000\n",
      "Class: 8, mIoU: 0.6624\n",
      "Class: 9, mIoU: 0.0472\n",
      "Class: 10, mIoU: 0.5583\n",
      "Class: 11, mIoU: 0.0000\n",
      "Class: 12, mIoU: 0.0000\n",
      "Class: 13, mIoU: 0.2414\n",
      "Class: 14, mIoU: 0.0276\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 2, Loss: 1.2604452934265136, mIoU: 16.97%\n",
      "Class: 0, mIoU: 0.4698\n",
      "Class: 1, mIoU: 0.2931\n",
      "Class: 2, mIoU: 0.6200\n",
      "Class: 3, mIoU: 0.0275\n",
      "Class: 4, mIoU: 0.0062\n",
      "Class: 5, mIoU: 0.0914\n",
      "Class: 6, mIoU: 0.0279\n",
      "Class: 7, mIoU: 0.0008\n",
      "Class: 8, mIoU: 0.6390\n",
      "Class: 9, mIoU: 0.0806\n",
      "Class: 10, mIoU: 0.6630\n",
      "Class: 11, mIoU: 0.0334\n",
      "Class: 12, mIoU: 0.0000\n",
      "Class: 13, mIoU: 0.2373\n",
      "Class: 14, mIoU: 0.0334\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 3, Loss: 0.8353231062889099, mIoU: 18.74%\n",
      "Class: 0, mIoU: 0.6306\n",
      "Class: 1, mIoU: 0.0752\n",
      "Class: 2, mIoU: 0.6441\n",
      "Class: 3, mIoU: 0.0523\n",
      "Class: 4, mIoU: 0.0235\n",
      "Class: 5, mIoU: 0.1013\n",
      "Class: 6, mIoU: 0.0140\n",
      "Class: 7, mIoU: 0.0026\n",
      "Class: 8, mIoU: 0.6921\n",
      "Class: 9, mIoU: 0.1590\n",
      "Class: 10, mIoU: 0.6422\n",
      "Class: 11, mIoU: 0.1102\n",
      "Class: 12, mIoU: 0.0000\n",
      "Class: 13, mIoU: 0.3694\n",
      "Class: 14, mIoU: 0.0435\n",
      "Class: 15, mIoU: 0.0008\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 4, Loss: 0.9923210468292236, mIoU: 19.01%\n",
      "Class: 0, mIoU: 0.5512\n",
      "Class: 1, mIoU: 0.1527\n",
      "Class: 2, mIoU: 0.6082\n",
      "Class: 3, mIoU: 0.0582\n",
      "Class: 4, mIoU: 0.0221\n",
      "Class: 5, mIoU: 0.1420\n",
      "Class: 6, mIoU: 0.1229\n",
      "Class: 7, mIoU: 0.0166\n",
      "Class: 8, mIoU: 0.6064\n",
      "Class: 9, mIoU: 0.0898\n",
      "Class: 10, mIoU: 0.6993\n",
      "Class: 11, mIoU: 0.1620\n",
      "Class: 12, mIoU: 0.0302\n",
      "Class: 13, mIoU: 0.3133\n",
      "Class: 14, mIoU: 0.0370\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 5, Loss: 1.4092140345573425, mIoU: 16.25%\n",
      "Class: 0, mIoU: 0.4523\n",
      "Class: 1, mIoU: 0.0889\n",
      "Class: 2, mIoU: 0.5199\n",
      "Class: 3, mIoU: 0.0404\n",
      "Class: 4, mIoU: 0.0000\n",
      "Class: 5, mIoU: 0.0916\n",
      "Class: 6, mIoU: 0.0619\n",
      "Class: 7, mIoU: 0.0225\n",
      "Class: 8, mIoU: 0.6891\n",
      "Class: 9, mIoU: 0.1009\n",
      "Class: 10, mIoU: 0.6643\n",
      "Class: 11, mIoU: 0.1348\n",
      "Class: 12, mIoU: 0.0244\n",
      "Class: 13, mIoU: 0.1721\n",
      "Class: 14, mIoU: 0.0180\n",
      "Class: 15, mIoU: 0.0029\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0045\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 6, Loss: 1.50590167427063, mIoU: 17.36%\n",
      "Class: 0, mIoU: 0.3502\n",
      "Class: 1, mIoU: 0.2565\n",
      "Class: 2, mIoU: 0.5813\n",
      "Class: 3, mIoU: 0.0545\n",
      "Class: 4, mIoU: 0.0168\n",
      "Class: 5, mIoU: 0.1185\n",
      "Class: 6, mIoU: 0.0825\n",
      "Class: 7, mIoU: 0.0517\n",
      "Class: 8, mIoU: 0.7006\n",
      "Class: 9, mIoU: 0.1377\n",
      "Class: 10, mIoU: 0.6229\n",
      "Class: 11, mIoU: 0.1173\n",
      "Class: 12, mIoU: 0.0111\n",
      "Class: 13, mIoU: 0.1755\n",
      "Class: 14, mIoU: 0.0218\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 7, Loss: 1.2707188954353332, mIoU: 17.41%\n",
      "Class: 0, mIoU: 0.5670\n",
      "Class: 1, mIoU: 0.1327\n",
      "Class: 2, mIoU: 0.5354\n",
      "Class: 3, mIoU: 0.0599\n",
      "Class: 4, mIoU: 0.0350\n",
      "Class: 5, mIoU: 0.0523\n",
      "Class: 6, mIoU: 0.0812\n",
      "Class: 7, mIoU: 0.0165\n",
      "Class: 8, mIoU: 0.5658\n",
      "Class: 9, mIoU: 0.1062\n",
      "Class: 10, mIoU: 0.7048\n",
      "Class: 11, mIoU: 0.1602\n",
      "Class: 12, mIoU: 0.0141\n",
      "Class: 13, mIoU: 0.2190\n",
      "Class: 14, mIoU: 0.0447\n",
      "Class: 15, mIoU: 0.0124\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 8, Loss: 1.2528015756607056, mIoU: 18.63%\n",
      "Class: 0, mIoU: 0.4534\n",
      "Class: 1, mIoU: 0.1389\n",
      "Class: 2, mIoU: 0.6514\n",
      "Class: 3, mIoU: 0.0751\n",
      "Class: 4, mIoU: 0.0521\n",
      "Class: 5, mIoU: 0.1272\n",
      "Class: 6, mIoU: 0.1124\n",
      "Class: 7, mIoU: 0.0734\n",
      "Class: 8, mIoU: 0.6698\n",
      "Class: 9, mIoU: 0.1177\n",
      "Class: 10, mIoU: 0.6573\n",
      "Class: 11, mIoU: 0.1397\n",
      "Class: 12, mIoU: 0.0026\n",
      "Class: 13, mIoU: 0.2319\n",
      "Class: 14, mIoU: 0.0355\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0006\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 9, Loss: 1.3511767616271972, mIoU: 19.36%\n",
      "Class: 0, mIoU: 0.4975\n",
      "Class: 1, mIoU: 0.1582\n",
      "Class: 2, mIoU: 0.6410\n",
      "Class: 3, mIoU: 0.0899\n",
      "Class: 4, mIoU: 0.0331\n",
      "Class: 5, mIoU: 0.0894\n",
      "Class: 6, mIoU: 0.1070\n",
      "Class: 7, mIoU: 0.0516\n",
      "Class: 8, mIoU: 0.6770\n",
      "Class: 9, mIoU: 0.1351\n",
      "Class: 10, mIoU: 0.7004\n",
      "Class: 11, mIoU: 0.1792\n",
      "Class: 12, mIoU: 0.0317\n",
      "Class: 13, mIoU: 0.2372\n",
      "Class: 14, mIoU: 0.0510\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 10, Loss: 1.1725187134742736, mIoU: 19.12%\n",
      "Class: 0, mIoU: 0.5122\n",
      "Class: 1, mIoU: 0.1779\n",
      "Class: 2, mIoU: 0.6142\n",
      "Class: 3, mIoU: 0.0660\n",
      "Class: 4, mIoU: 0.0626\n",
      "Class: 5, mIoU: 0.0830\n",
      "Class: 6, mIoU: 0.1117\n",
      "Class: 7, mIoU: 0.0323\n",
      "Class: 8, mIoU: 0.7132\n",
      "Class: 9, mIoU: 0.1355\n",
      "Class: 10, mIoU: 0.6723\n",
      "Class: 11, mIoU: 0.1518\n",
      "Class: 12, mIoU: 0.0236\n",
      "Class: 13, mIoU: 0.2372\n",
      "Class: 14, mIoU: 0.0335\n",
      "Class: 15, mIoU: 0.0002\n",
      "Class: 16, mIoU: 0.0044\n",
      "Class: 17, mIoU: 0.0001\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 11, Loss: 0.8786703786849975, mIoU: 20.13%\n",
      "Class: 0, mIoU: 0.6409\n",
      "Class: 1, mIoU: 0.0892\n",
      "Class: 2, mIoU: 0.5593\n",
      "Class: 3, mIoU: 0.0427\n",
      "Class: 4, mIoU: 0.0668\n",
      "Class: 5, mIoU: 0.1030\n",
      "Class: 6, mIoU: 0.0991\n",
      "Class: 7, mIoU: 0.0188\n",
      "Class: 8, mIoU: 0.6787\n",
      "Class: 9, mIoU: 0.1287\n",
      "Class: 10, mIoU: 0.6072\n",
      "Class: 11, mIoU: 0.1633\n",
      "Class: 12, mIoU: 0.0330\n",
      "Class: 13, mIoU: 0.5362\n",
      "Class: 14, mIoU: 0.0447\n",
      "Class: 15, mIoU: 0.0008\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0109\n",
      "Class: 18, mIoU: 0.0017\n",
      "Epoch: 12, Loss: 1.0552155175209046, mIoU: 19.94%\n",
      "Class: 0, mIoU: 0.5055\n",
      "Class: 1, mIoU: 0.1409\n",
      "Class: 2, mIoU: 0.6649\n",
      "Class: 3, mIoU: 0.0584\n",
      "Class: 4, mIoU: 0.0244\n",
      "Class: 5, mIoU: 0.1145\n",
      "Class: 6, mIoU: 0.0782\n",
      "Class: 7, mIoU: 0.1043\n",
      "Class: 8, mIoU: 0.7355\n",
      "Class: 9, mIoU: 0.1645\n",
      "Class: 10, mIoU: 0.6160\n",
      "Class: 11, mIoU: 0.1670\n",
      "Class: 12, mIoU: 0.0225\n",
      "Class: 13, mIoU: 0.2803\n",
      "Class: 14, mIoU: 0.0939\n",
      "Class: 15, mIoU: 0.0001\n",
      "Class: 16, mIoU: 0.0011\n",
      "Class: 17, mIoU: 0.0173\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 13, Loss: 0.8799162302017212, mIoU: 20.28%\n",
      "Class: 0, mIoU: 0.5915\n",
      "Class: 1, mIoU: 0.1601\n",
      "Class: 2, mIoU: 0.6622\n",
      "Class: 3, mIoU: 0.0577\n",
      "Class: 4, mIoU: 0.0714\n",
      "Class: 5, mIoU: 0.1480\n",
      "Class: 6, mIoU: 0.1262\n",
      "Class: 7, mIoU: 0.0610\n",
      "Class: 8, mIoU: 0.7186\n",
      "Class: 9, mIoU: 0.0987\n",
      "Class: 10, mIoU: 0.5862\n",
      "Class: 11, mIoU: 0.1533\n",
      "Class: 12, mIoU: 0.0271\n",
      "Class: 13, mIoU: 0.3401\n",
      "Class: 14, mIoU: 0.0397\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0007\n",
      "Class: 17, mIoU: 0.0114\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 14, Loss: 0.8659378242492676, mIoU: 21.89%\n",
      "Class: 0, mIoU: 0.6665\n",
      "Class: 1, mIoU: 0.1999\n",
      "Class: 2, mIoU: 0.6492\n",
      "Class: 3, mIoU: 0.0909\n",
      "Class: 4, mIoU: 0.0337\n",
      "Class: 5, mIoU: 0.1290\n",
      "Class: 6, mIoU: 0.1384\n",
      "Class: 7, mIoU: 0.0595\n",
      "Class: 8, mIoU: 0.7068\n",
      "Class: 9, mIoU: 0.1258\n",
      "Class: 10, mIoU: 0.6930\n",
      "Class: 11, mIoU: 0.1856\n",
      "Class: 12, mIoU: 0.0213\n",
      "Class: 13, mIoU: 0.4164\n",
      "Class: 14, mIoU: 0.0299\n",
      "Class: 15, mIoU: 0.0000\n",
      "Class: 16, mIoU: 0.0115\n",
      "Class: 17, mIoU: 0.0014\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 15, Loss: 0.9688650250434876, mIoU: 20.28%\n",
      "Class: 0, mIoU: 0.6033\n",
      "Class: 1, mIoU: 0.0568\n",
      "Class: 2, mIoU: 0.6136\n",
      "Class: 3, mIoU: 0.0799\n",
      "Class: 4, mIoU: 0.0310\n",
      "Class: 5, mIoU: 0.0856\n",
      "Class: 6, mIoU: 0.0780\n",
      "Class: 7, mIoU: 0.0519\n",
      "Class: 8, mIoU: 0.6881\n",
      "Class: 9, mIoU: 0.1431\n",
      "Class: 10, mIoU: 0.6728\n",
      "Class: 11, mIoU: 0.1784\n",
      "Class: 12, mIoU: 0.0286\n",
      "Class: 13, mIoU: 0.4412\n",
      "Class: 14, mIoU: 0.0669\n",
      "Class: 15, mIoU: 0.0006\n",
      "Class: 16, mIoU: 0.0141\n",
      "Class: 17, mIoU: 0.0195\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 16, Loss: 1.049547338962555, mIoU: 21.66%\n",
      "Class: 0, mIoU: 0.5147\n",
      "Class: 1, mIoU: 0.2416\n",
      "Class: 2, mIoU: 0.6798\n",
      "Class: 3, mIoU: 0.0636\n",
      "Class: 4, mIoU: 0.0431\n",
      "Class: 5, mIoU: 0.1480\n",
      "Class: 6, mIoU: 0.1330\n",
      "Class: 7, mIoU: 0.0747\n",
      "Class: 8, mIoU: 0.7405\n",
      "Class: 9, mIoU: 0.1507\n",
      "Class: 10, mIoU: 0.7415\n",
      "Class: 11, mIoU: 0.2361\n",
      "Class: 12, mIoU: 0.0147\n",
      "Class: 13, mIoU: 0.2700\n",
      "Class: 14, mIoU: 0.0578\n",
      "Class: 15, mIoU: 0.0003\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0043\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 17, Loss: 1.0380744013786316, mIoU: 20.60%\n",
      "Class: 0, mIoU: 0.5346\n",
      "Class: 1, mIoU: 0.0990\n",
      "Class: 2, mIoU: 0.6400\n",
      "Class: 3, mIoU: 0.0450\n",
      "Class: 4, mIoU: 0.0321\n",
      "Class: 5, mIoU: 0.1090\n",
      "Class: 6, mIoU: 0.1495\n",
      "Class: 7, mIoU: 0.0180\n",
      "Class: 8, mIoU: 0.7320\n",
      "Class: 9, mIoU: 0.1522\n",
      "Class: 10, mIoU: 0.6994\n",
      "Class: 11, mIoU: 0.2472\n",
      "Class: 12, mIoU: 0.0135\n",
      "Class: 13, mIoU: 0.3426\n",
      "Class: 14, mIoU: 0.0840\n",
      "Class: 15, mIoU: 0.0100\n",
      "Class: 16, mIoU: 0.0002\n",
      "Class: 17, mIoU: 0.0054\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 18, Loss: 1.0682548332214354, mIoU: 18.78%\n",
      "Class: 0, mIoU: 0.6009\n",
      "Class: 1, mIoU: 0.0734\n",
      "Class: 2, mIoU: 0.5041\n",
      "Class: 3, mIoU: 0.0384\n",
      "Class: 4, mIoU: 0.0502\n",
      "Class: 5, mIoU: 0.0806\n",
      "Class: 6, mIoU: 0.1119\n",
      "Class: 7, mIoU: 0.0238\n",
      "Class: 8, mIoU: 0.5835\n",
      "Class: 9, mIoU: 0.0719\n",
      "Class: 10, mIoU: 0.7347\n",
      "Class: 11, mIoU: 0.1850\n",
      "Class: 12, mIoU: 0.0042\n",
      "Class: 13, mIoU: 0.4372\n",
      "Class: 14, mIoU: 0.0586\n",
      "Class: 15, mIoU: 0.0037\n",
      "Class: 16, mIoU: 0.0002\n",
      "Class: 17, mIoU: 0.0058\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 19, Loss: 0.8959845089912415, mIoU: 20.80%\n",
      "Class: 0, mIoU: 0.6101\n",
      "Class: 1, mIoU: 0.1226\n",
      "Class: 2, mIoU: 0.5865\n",
      "Class: 3, mIoU: 0.0588\n",
      "Class: 4, mIoU: 0.0572\n",
      "Class: 5, mIoU: 0.1271\n",
      "Class: 6, mIoU: 0.1200\n",
      "Class: 7, mIoU: 0.0443\n",
      "Class: 8, mIoU: 0.6998\n",
      "Class: 9, mIoU: 0.1129\n",
      "Class: 10, mIoU: 0.6446\n",
      "Class: 11, mIoU: 0.1793\n",
      "Class: 12, mIoU: 0.0293\n",
      "Class: 13, mIoU: 0.4684\n",
      "Class: 14, mIoU: 0.0721\n",
      "Class: 15, mIoU: 0.0152\n",
      "Class: 16, mIoU: 0.0011\n",
      "Class: 17, mIoU: 0.0026\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 20, Loss: 1.2505366048812867, mIoU: 20.22%\n",
      "Class: 0, mIoU: 0.4694\n",
      "Class: 1, mIoU: 0.1902\n",
      "Class: 2, mIoU: 0.5404\n",
      "Class: 3, mIoU: 0.0787\n",
      "Class: 4, mIoU: 0.0570\n",
      "Class: 5, mIoU: 0.1362\n",
      "Class: 6, mIoU: 0.1512\n",
      "Class: 7, mIoU: 0.0410\n",
      "Class: 8, mIoU: 0.7153\n",
      "Class: 9, mIoU: 0.1400\n",
      "Class: 10, mIoU: 0.6559\n",
      "Class: 11, mIoU: 0.2260\n",
      "Class: 12, mIoU: 0.0278\n",
      "Class: 13, mIoU: 0.2857\n",
      "Class: 14, mIoU: 0.0752\n",
      "Class: 15, mIoU: 0.0102\n",
      "Class: 16, mIoU: 0.0367\n",
      "Class: 17, mIoU: 0.0036\n",
      "Class: 18, mIoU: 0.0017\n",
      "Epoch: 21, Loss: 0.9306047308444977, mIoU: 22.09%\n",
      "Class: 0, mIoU: 0.5861\n",
      "Class: 1, mIoU: 0.2512\n",
      "Class: 2, mIoU: 0.6608\n",
      "Class: 3, mIoU: 0.0921\n",
      "Class: 4, mIoU: 0.1016\n",
      "Class: 5, mIoU: 0.1559\n",
      "Class: 6, mIoU: 0.1309\n",
      "Class: 7, mIoU: 0.0659\n",
      "Class: 8, mIoU: 0.7118\n",
      "Class: 9, mIoU: 0.1118\n",
      "Class: 10, mIoU: 0.6614\n",
      "Class: 11, mIoU: 0.2255\n",
      "Class: 12, mIoU: 0.0135\n",
      "Class: 13, mIoU: 0.3617\n",
      "Class: 14, mIoU: 0.0615\n",
      "Class: 15, mIoU: 0.0001\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0046\n",
      "Class: 18, mIoU: 0.0006\n",
      "Epoch: 22, Loss: 1.0550168662071229, mIoU: 20.21%\n",
      "Class: 0, mIoU: 0.6309\n",
      "Class: 1, mIoU: 0.1501\n",
      "Class: 2, mIoU: 0.5541\n",
      "Class: 3, mIoU: 0.0350\n",
      "Class: 4, mIoU: 0.0446\n",
      "Class: 5, mIoU: 0.1343\n",
      "Class: 6, mIoU: 0.1118\n",
      "Class: 7, mIoU: 0.0489\n",
      "Class: 8, mIoU: 0.7437\n",
      "Class: 9, mIoU: 0.1445\n",
      "Class: 10, mIoU: 0.6996\n",
      "Class: 11, mIoU: 0.1687\n",
      "Class: 12, mIoU: 0.0086\n",
      "Class: 13, mIoU: 0.3213\n",
      "Class: 14, mIoU: 0.0356\n",
      "Class: 15, mIoU: 0.0072\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0013\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 23, Loss: 1.945310133934021, mIoU: 17.81%\n",
      "Class: 0, mIoU: 0.4715\n",
      "Class: 1, mIoU: 0.1878\n",
      "Class: 2, mIoU: 0.5576\n",
      "Class: 3, mIoU: 0.0770\n",
      "Class: 4, mIoU: 0.0290\n",
      "Class: 5, mIoU: 0.0799\n",
      "Class: 6, mIoU: 0.1598\n",
      "Class: 7, mIoU: 0.0361\n",
      "Class: 8, mIoU: 0.7119\n",
      "Class: 9, mIoU: 0.1343\n",
      "Class: 10, mIoU: 0.6211\n",
      "Class: 11, mIoU: 0.1852\n",
      "Class: 12, mIoU: 0.0080\n",
      "Class: 13, mIoU: 0.1104\n",
      "Class: 14, mIoU: 0.0085\n",
      "Class: 15, mIoU: 0.0018\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0041\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 24, Loss: 1.6735304832458495, mIoU: 18.66%\n",
      "Class: 0, mIoU: 0.2585\n",
      "Class: 1, mIoU: 0.1822\n",
      "Class: 2, mIoU: 0.6528\n",
      "Class: 3, mIoU: 0.0437\n",
      "Class: 4, mIoU: 0.0696\n",
      "Class: 5, mIoU: 0.1310\n",
      "Class: 6, mIoU: 0.0893\n",
      "Class: 7, mIoU: 0.0548\n",
      "Class: 8, mIoU: 0.7281\n",
      "Class: 9, mIoU: 0.1259\n",
      "Class: 10, mIoU: 0.6805\n",
      "Class: 11, mIoU: 0.1945\n",
      "Class: 12, mIoU: 0.0268\n",
      "Class: 13, mIoU: 0.2164\n",
      "Class: 14, mIoU: 0.0468\n",
      "Class: 15, mIoU: 0.0203\n",
      "Class: 16, mIoU: 0.0113\n",
      "Class: 17, mIoU: 0.0117\n",
      "Class: 18, mIoU: 0.0006\n",
      "Epoch: 25, Loss: 1.0295688090324402, mIoU: 21.99%\n",
      "Class: 0, mIoU: 0.5274\n",
      "Class: 1, mIoU: 0.2390\n",
      "Class: 2, mIoU: 0.6725\n",
      "Class: 3, mIoU: 0.1040\n",
      "Class: 4, mIoU: 0.0707\n",
      "Class: 5, mIoU: 0.1219\n",
      "Class: 6, mIoU: 0.1429\n",
      "Class: 7, mIoU: 0.0646\n",
      "Class: 8, mIoU: 0.7498\n",
      "Class: 9, mIoU: 0.1632\n",
      "Class: 10, mIoU: 0.7127\n",
      "Class: 11, mIoU: 0.2017\n",
      "Class: 12, mIoU: 0.0189\n",
      "Class: 13, mIoU: 0.3147\n",
      "Class: 14, mIoU: 0.0524\n",
      "Class: 15, mIoU: 0.0090\n",
      "Class: 16, mIoU: 0.0075\n",
      "Class: 17, mIoU: 0.0048\n",
      "Class: 18, mIoU: 0.0011\n",
      "Epoch: 26, Loss: 1.3582180728912354, mIoU: 20.55%\n",
      "Class: 0, mIoU: 0.4996\n",
      "Class: 1, mIoU: 0.2654\n",
      "Class: 2, mIoU: 0.6254\n",
      "Class: 3, mIoU: 0.0853\n",
      "Class: 4, mIoU: 0.0241\n",
      "Class: 5, mIoU: 0.1477\n",
      "Class: 6, mIoU: 0.1402\n",
      "Class: 7, mIoU: 0.0484\n",
      "Class: 8, mIoU: 0.6708\n",
      "Class: 9, mIoU: 0.0982\n",
      "Class: 10, mIoU: 0.7196\n",
      "Class: 11, mIoU: 0.1993\n",
      "Class: 12, mIoU: 0.0108\n",
      "Class: 13, mIoU: 0.3438\n",
      "Class: 14, mIoU: 0.0137\n",
      "Class: 15, mIoU: 0.0018\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0103\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 27, Loss: 1.100683557510376, mIoU: 19.96%\n",
      "Class: 0, mIoU: 0.5506\n",
      "Class: 1, mIoU: 0.0846\n",
      "Class: 2, mIoU: 0.6308\n",
      "Class: 3, mIoU: 0.0508\n",
      "Class: 4, mIoU: 0.0802\n",
      "Class: 5, mIoU: 0.1279\n",
      "Class: 6, mIoU: 0.0976\n",
      "Class: 7, mIoU: 0.0494\n",
      "Class: 8, mIoU: 0.7151\n",
      "Class: 9, mIoU: 0.1196\n",
      "Class: 10, mIoU: 0.7026\n",
      "Class: 11, mIoU: 0.0835\n",
      "Class: 12, mIoU: 0.0077\n",
      "Class: 13, mIoU: 0.4495\n",
      "Class: 14, mIoU: 0.0255\n",
      "Class: 15, mIoU: 0.0030\n",
      "Class: 16, mIoU: 0.0048\n",
      "Class: 17, mIoU: 0.0088\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 28, Loss: 1.6914245519638063, mIoU: 16.92%\n",
      "Class: 0, mIoU: 0.3936\n",
      "Class: 1, mIoU: 0.1146\n",
      "Class: 2, mIoU: 0.5829\n",
      "Class: 3, mIoU: 0.0408\n",
      "Class: 4, mIoU: 0.0210\n",
      "Class: 5, mIoU: 0.0916\n",
      "Class: 6, mIoU: 0.0767\n",
      "Class: 7, mIoU: 0.0255\n",
      "Class: 8, mIoU: 0.6796\n",
      "Class: 9, mIoU: 0.0643\n",
      "Class: 10, mIoU: 0.7117\n",
      "Class: 11, mIoU: 0.0730\n",
      "Class: 12, mIoU: 0.0030\n",
      "Class: 13, mIoU: 0.2512\n",
      "Class: 14, mIoU: 0.0524\n",
      "Class: 15, mIoU: 0.0217\n",
      "Class: 16, mIoU: 0.0036\n",
      "Class: 17, mIoU: 0.0085\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 29, Loss: 1.3122517499923707, mIoU: 18.45%\n",
      "Class: 0, mIoU: 0.5181\n",
      "Class: 1, mIoU: 0.1672\n",
      "Class: 2, mIoU: 0.6022\n",
      "Class: 3, mIoU: 0.0507\n",
      "Class: 4, mIoU: 0.0555\n",
      "Class: 5, mIoU: 0.0932\n",
      "Class: 6, mIoU: 0.0997\n",
      "Class: 7, mIoU: 0.0632\n",
      "Class: 8, mIoU: 0.6761\n",
      "Class: 9, mIoU: 0.0978\n",
      "Class: 10, mIoU: 0.6663\n",
      "Class: 11, mIoU: 0.0953\n",
      "Class: 12, mIoU: 0.0018\n",
      "Class: 13, mIoU: 0.2903\n",
      "Class: 14, mIoU: 0.0235\n",
      "Class: 15, mIoU: 0.0001\n",
      "Class: 16, mIoU: 0.0006\n",
      "Class: 17, mIoU: 0.0035\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 30, Loss: 0.9653864498138428, mIoU: 22.30%\n",
      "Class: 0, mIoU: 0.6277\n",
      "Class: 1, mIoU: 0.2066\n",
      "Class: 2, mIoU: 0.6508\n",
      "Class: 3, mIoU: 0.0543\n",
      "Class: 4, mIoU: 0.0589\n",
      "Class: 5, mIoU: 0.1423\n",
      "Class: 6, mIoU: 0.1439\n",
      "Class: 7, mIoU: 0.0614\n",
      "Class: 8, mIoU: 0.7184\n",
      "Class: 9, mIoU: 0.1315\n",
      "Class: 10, mIoU: 0.7240\n",
      "Class: 11, mIoU: 0.1999\n",
      "Class: 12, mIoU: 0.0372\n",
      "Class: 13, mIoU: 0.4211\n",
      "Class: 14, mIoU: 0.0345\n",
      "Class: 15, mIoU: 0.0006\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0235\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 31, Loss: 1.3276210203170777, mIoU: 17.85%\n",
      "Class: 0, mIoU: 0.4810\n",
      "Class: 1, mIoU: 0.1309\n",
      "Class: 2, mIoU: 0.5494\n",
      "Class: 3, mIoU: 0.0418\n",
      "Class: 4, mIoU: 0.0584\n",
      "Class: 5, mIoU: 0.1360\n",
      "Class: 6, mIoU: 0.0847\n",
      "Class: 7, mIoU: 0.0097\n",
      "Class: 8, mIoU: 0.6843\n",
      "Class: 9, mIoU: 0.1179\n",
      "Class: 10, mIoU: 0.6426\n",
      "Class: 11, mIoU: 0.1255\n",
      "Class: 12, mIoU: 0.0044\n",
      "Class: 13, mIoU: 0.2727\n",
      "Class: 14, mIoU: 0.0336\n",
      "Class: 15, mIoU: 0.0145\n",
      "Class: 16, mIoU: 0.0041\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 32, Loss: 0.8627985644340516, mIoU: 22.40%\n",
      "Class: 0, mIoU: 0.6455\n",
      "Class: 1, mIoU: 0.2121\n",
      "Class: 2, mIoU: 0.6407\n",
      "Class: 3, mIoU: 0.0911\n",
      "Class: 4, mIoU: 0.0463\n",
      "Class: 5, mIoU: 0.1595\n",
      "Class: 6, mIoU: 0.0835\n",
      "Class: 7, mIoU: 0.0664\n",
      "Class: 8, mIoU: 0.7254\n",
      "Class: 9, mIoU: 0.1259\n",
      "Class: 10, mIoU: 0.7136\n",
      "Class: 11, mIoU: 0.2301\n",
      "Class: 12, mIoU: 0.0230\n",
      "Class: 13, mIoU: 0.3924\n",
      "Class: 14, mIoU: 0.0669\n",
      "Class: 15, mIoU: 0.0153\n",
      "Class: 16, mIoU: 0.0065\n",
      "Class: 17, mIoU: 0.0111\n",
      "Class: 18, mIoU: 0.0012\n",
      "Epoch: 33, Loss: 0.9703350207805633, mIoU: 21.90%\n",
      "Class: 0, mIoU: 0.5908\n",
      "Class: 1, mIoU: 0.1772\n",
      "Class: 2, mIoU: 0.6078\n",
      "Class: 3, mIoU: 0.0886\n",
      "Class: 4, mIoU: 0.0440\n",
      "Class: 5, mIoU: 0.1429\n",
      "Class: 6, mIoU: 0.1188\n",
      "Class: 7, mIoU: 0.0441\n",
      "Class: 8, mIoU: 0.7479\n",
      "Class: 9, mIoU: 0.1566\n",
      "Class: 10, mIoU: 0.6981\n",
      "Class: 11, mIoU: 0.2331\n",
      "Class: 12, mIoU: 0.0148\n",
      "Class: 13, mIoU: 0.3999\n",
      "Class: 14, mIoU: 0.0607\n",
      "Class: 15, mIoU: 0.0260\n",
      "Class: 16, mIoU: 0.0022\n",
      "Class: 17, mIoU: 0.0052\n",
      "Class: 18, mIoU: 0.0026\n",
      "Epoch: 34, Loss: 0.8634593839645386, mIoU: 22.47%\n",
      "Class: 0, mIoU: 0.6362\n",
      "Class: 1, mIoU: 0.1718\n",
      "Class: 2, mIoU: 0.6210\n",
      "Class: 3, mIoU: 0.0720\n",
      "Class: 4, mIoU: 0.0717\n",
      "Class: 5, mIoU: 0.1607\n",
      "Class: 6, mIoU: 0.1285\n",
      "Class: 7, mIoU: 0.0855\n",
      "Class: 8, mIoU: 0.7345\n",
      "Class: 9, mIoU: 0.1327\n",
      "Class: 10, mIoU: 0.6647\n",
      "Class: 11, mIoU: 0.2206\n",
      "Class: 12, mIoU: 0.0168\n",
      "Class: 13, mIoU: 0.4471\n",
      "Class: 14, mIoU: 0.0642\n",
      "Class: 15, mIoU: 0.0265\n",
      "Class: 16, mIoU: 0.0062\n",
      "Class: 17, mIoU: 0.0088\n",
      "Class: 18, mIoU: 0.0002\n",
      "Epoch: 35, Loss: 0.9727165622711181, mIoU: 22.42%\n",
      "Class: 0, mIoU: 0.6014\n",
      "Class: 1, mIoU: 0.2221\n",
      "Class: 2, mIoU: 0.5992\n",
      "Class: 3, mIoU: 0.0916\n",
      "Class: 4, mIoU: 0.0372\n",
      "Class: 5, mIoU: 0.1642\n",
      "Class: 6, mIoU: 0.1224\n",
      "Class: 7, mIoU: 0.0704\n",
      "Class: 8, mIoU: 0.7469\n",
      "Class: 9, mIoU: 0.1399\n",
      "Class: 10, mIoU: 0.6972\n",
      "Class: 11, mIoU: 0.2209\n",
      "Class: 12, mIoU: 0.0173\n",
      "Class: 13, mIoU: 0.4269\n",
      "Class: 14, mIoU: 0.0615\n",
      "Class: 15, mIoU: 0.0348\n",
      "Class: 16, mIoU: 0.0001\n",
      "Class: 17, mIoU: 0.0060\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 36, Loss: 0.8847234342098236, mIoU: 23.52%\n",
      "Class: 0, mIoU: 0.6318\n",
      "Class: 1, mIoU: 0.2016\n",
      "Class: 2, mIoU: 0.6566\n",
      "Class: 3, mIoU: 0.0793\n",
      "Class: 4, mIoU: 0.0661\n",
      "Class: 5, mIoU: 0.1942\n",
      "Class: 6, mIoU: 0.1488\n",
      "Class: 7, mIoU: 0.0899\n",
      "Class: 8, mIoU: 0.7367\n",
      "Class: 9, mIoU: 0.1328\n",
      "Class: 10, mIoU: 0.7135\n",
      "Class: 11, mIoU: 0.2397\n",
      "Class: 12, mIoU: 0.0362\n",
      "Class: 13, mIoU: 0.4196\n",
      "Class: 14, mIoU: 0.0666\n",
      "Class: 15, mIoU: 0.0277\n",
      "Class: 16, mIoU: 0.0056\n",
      "Class: 17, mIoU: 0.0207\n",
      "Class: 18, mIoU: 0.0007\n",
      "Epoch: 37, Loss: 0.9513600771427154, mIoU: 21.79%\n",
      "Class: 0, mIoU: 0.6164\n",
      "Class: 1, mIoU: 0.1520\n",
      "Class: 2, mIoU: 0.6595\n",
      "Class: 3, mIoU: 0.0891\n",
      "Class: 4, mIoU: 0.0529\n",
      "Class: 5, mIoU: 0.1289\n",
      "Class: 6, mIoU: 0.1027\n",
      "Class: 7, mIoU: 0.0681\n",
      "Class: 8, mIoU: 0.7474\n",
      "Class: 9, mIoU: 0.1369\n",
      "Class: 10, mIoU: 0.6917\n",
      "Class: 11, mIoU: 0.2118\n",
      "Class: 12, mIoU: 0.0040\n",
      "Class: 13, mIoU: 0.4064\n",
      "Class: 14, mIoU: 0.0474\n",
      "Class: 15, mIoU: 0.0077\n",
      "Class: 16, mIoU: 0.0100\n",
      "Class: 17, mIoU: 0.0050\n",
      "Class: 18, mIoU: 0.0022\n",
      "Epoch: 38, Loss: 2.1170225925445556, mIoU: 14.47%\n",
      "Class: 0, mIoU: 0.3171\n",
      "Class: 1, mIoU: 0.0302\n",
      "Class: 2, mIoU: 0.5009\n",
      "Class: 3, mIoU: 0.0290\n",
      "Class: 4, mIoU: 0.0186\n",
      "Class: 5, mIoU: 0.0589\n",
      "Class: 6, mIoU: 0.0452\n",
      "Class: 7, mIoU: 0.0130\n",
      "Class: 8, mIoU: 0.6006\n",
      "Class: 9, mIoU: 0.0899\n",
      "Class: 10, mIoU: 0.6888\n",
      "Class: 11, mIoU: 0.1153\n",
      "Class: 12, mIoU: 0.0173\n",
      "Class: 13, mIoU: 0.1957\n",
      "Class: 14, mIoU: 0.0228\n",
      "Class: 15, mIoU: 0.0037\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0026\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 39, Loss: 1.0757799963951111, mIoU: 21.03%\n",
      "Class: 0, mIoU: 0.5507\n",
      "Class: 1, mIoU: 0.1850\n",
      "Class: 2, mIoU: 0.6121\n",
      "Class: 3, mIoU: 0.0722\n",
      "Class: 4, mIoU: 0.0490\n",
      "Class: 5, mIoU: 0.1400\n",
      "Class: 6, mIoU: 0.1215\n",
      "Class: 7, mIoU: 0.0568\n",
      "Class: 8, mIoU: 0.7194\n",
      "Class: 9, mIoU: 0.1476\n",
      "Class: 10, mIoU: 0.7028\n",
      "Class: 11, mIoU: 0.1798\n",
      "Class: 12, mIoU: 0.0297\n",
      "Class: 13, mIoU: 0.3107\n",
      "Class: 14, mIoU: 0.0796\n",
      "Class: 15, mIoU: 0.0200\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0161\n",
      "Class: 18, mIoU: 0.0033\n",
      "Epoch: 40, Loss: 1.07343110704422, mIoU: 21.51%\n",
      "Class: 0, mIoU: 0.5409\n",
      "Class: 1, mIoU: 0.1634\n",
      "Class: 2, mIoU: 0.6245\n",
      "Class: 3, mIoU: 0.0943\n",
      "Class: 4, mIoU: 0.0690\n",
      "Class: 5, mIoU: 0.1370\n",
      "Class: 6, mIoU: 0.1242\n",
      "Class: 7, mIoU: 0.0713\n",
      "Class: 8, mIoU: 0.7396\n",
      "Class: 9, mIoU: 0.1507\n",
      "Class: 10, mIoU: 0.7062\n",
      "Class: 11, mIoU: 0.2270\n",
      "Class: 12, mIoU: 0.0167\n",
      "Class: 13, mIoU: 0.3266\n",
      "Class: 14, mIoU: 0.0435\n",
      "Class: 15, mIoU: 0.0473\n",
      "Class: 16, mIoU: 0.0003\n",
      "Class: 17, mIoU: 0.0044\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 41, Loss: 1.1614138288497924, mIoU: 21.11%\n",
      "Class: 0, mIoU: 0.5243\n",
      "Class: 1, mIoU: 0.2032\n",
      "Class: 2, mIoU: 0.6585\n",
      "Class: 3, mIoU: 0.0804\n",
      "Class: 4, mIoU: 0.0546\n",
      "Class: 5, mIoU: 0.1252\n",
      "Class: 6, mIoU: 0.1271\n",
      "Class: 7, mIoU: 0.0578\n",
      "Class: 8, mIoU: 0.7308\n",
      "Class: 9, mIoU: 0.1406\n",
      "Class: 10, mIoU: 0.7268\n",
      "Class: 11, mIoU: 0.1970\n",
      "Class: 12, mIoU: 0.0195\n",
      "Class: 13, mIoU: 0.2648\n",
      "Class: 14, mIoU: 0.0653\n",
      "Class: 15, mIoU: 0.0264\n",
      "Class: 16, mIoU: 0.0012\n",
      "Class: 17, mIoU: 0.0065\n",
      "Class: 18, mIoU: 0.0004\n",
      "Epoch: 42, Loss: 1.0258490324020386, mIoU: 22.15%\n",
      "Class: 0, mIoU: 0.5838\n",
      "Class: 1, mIoU: 0.1720\n",
      "Class: 2, mIoU: 0.6575\n",
      "Class: 3, mIoU: 0.0791\n",
      "Class: 4, mIoU: 0.0541\n",
      "Class: 5, mIoU: 0.1498\n",
      "Class: 6, mIoU: 0.1117\n",
      "Class: 7, mIoU: 0.0561\n",
      "Class: 8, mIoU: 0.7219\n",
      "Class: 9, mIoU: 0.1483\n",
      "Class: 10, mIoU: 0.7229\n",
      "Class: 11, mIoU: 0.2362\n",
      "Class: 12, mIoU: 0.0266\n",
      "Class: 13, mIoU: 0.3477\n",
      "Class: 14, mIoU: 0.0649\n",
      "Class: 15, mIoU: 0.0423\n",
      "Class: 16, mIoU: 0.0022\n",
      "Class: 17, mIoU: 0.0303\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 43, Loss: 0.9081118474006653, mIoU: 23.09%\n",
      "Class: 0, mIoU: 0.6298\n",
      "Class: 1, mIoU: 0.2007\n",
      "Class: 2, mIoU: 0.6631\n",
      "Class: 3, mIoU: 0.0915\n",
      "Class: 4, mIoU: 0.0764\n",
      "Class: 5, mIoU: 0.1851\n",
      "Class: 6, mIoU: 0.1223\n",
      "Class: 7, mIoU: 0.0722\n",
      "Class: 8, mIoU: 0.7380\n",
      "Class: 9, mIoU: 0.1495\n",
      "Class: 10, mIoU: 0.7233\n",
      "Class: 11, mIoU: 0.2069\n",
      "Class: 12, mIoU: 0.0116\n",
      "Class: 13, mIoU: 0.4183\n",
      "Class: 14, mIoU: 0.0665\n",
      "Class: 15, mIoU: 0.0114\n",
      "Class: 16, mIoU: 0.0017\n",
      "Class: 17, mIoU: 0.0186\n",
      "Class: 18, mIoU: 0.0001\n",
      "Epoch: 44, Loss: 1.0436723608970642, mIoU: 21.71%\n",
      "Class: 0, mIoU: 0.5655\n",
      "Class: 1, mIoU: 0.1511\n",
      "Class: 2, mIoU: 0.6629\n",
      "Class: 3, mIoU: 0.0642\n",
      "Class: 4, mIoU: 0.0951\n",
      "Class: 5, mIoU: 0.1561\n",
      "Class: 6, mIoU: 0.1446\n",
      "Class: 7, mIoU: 0.0745\n",
      "Class: 8, mIoU: 0.7189\n",
      "Class: 9, mIoU: 0.1317\n",
      "Class: 10, mIoU: 0.7036\n",
      "Class: 11, mIoU: 0.1978\n",
      "Class: 12, mIoU: 0.0038\n",
      "Class: 13, mIoU: 0.3846\n",
      "Class: 14, mIoU: 0.0552\n",
      "Class: 15, mIoU: 0.0072\n",
      "Class: 16, mIoU: 0.0007\n",
      "Class: 17, mIoU: 0.0067\n",
      "Class: 18, mIoU: 0.0005\n",
      "Epoch: 45, Loss: 1.0072384901046754, mIoU: 22.40%\n",
      "Class: 0, mIoU: 0.5887\n",
      "Class: 1, mIoU: 0.1505\n",
      "Class: 2, mIoU: 0.6467\n",
      "Class: 3, mIoU: 0.0717\n",
      "Class: 4, mIoU: 0.0789\n",
      "Class: 5, mIoU: 0.1698\n",
      "Class: 6, mIoU: 0.1272\n",
      "Class: 7, mIoU: 0.0688\n",
      "Class: 8, mIoU: 0.6954\n",
      "Class: 9, mIoU: 0.1452\n",
      "Class: 10, mIoU: 0.7255\n",
      "Class: 11, mIoU: 0.2123\n",
      "Class: 12, mIoU: 0.0217\n",
      "Class: 13, mIoU: 0.4100\n",
      "Class: 14, mIoU: 0.0682\n",
      "Class: 15, mIoU: 0.0432\n",
      "Class: 16, mIoU: 0.0051\n",
      "Class: 17, mIoU: 0.0258\n",
      "Class: 18, mIoU: 0.0009\n",
      "Epoch: 46, Loss: 1.03089155626297, mIoU: 22.09%\n",
      "Class: 0, mIoU: 0.5766\n",
      "Class: 1, mIoU: 0.2014\n",
      "Class: 2, mIoU: 0.6251\n",
      "Class: 3, mIoU: 0.0777\n",
      "Class: 4, mIoU: 0.0619\n",
      "Class: 5, mIoU: 0.1270\n",
      "Class: 6, mIoU: 0.1293\n",
      "Class: 7, mIoU: 0.0654\n",
      "Class: 8, mIoU: 0.7336\n",
      "Class: 9, mIoU: 0.1475\n",
      "Class: 10, mIoU: 0.7258\n",
      "Class: 11, mIoU: 0.2035\n",
      "Class: 12, mIoU: 0.0220\n",
      "Class: 13, mIoU: 0.3945\n",
      "Class: 14, mIoU: 0.0633\n",
      "Class: 15, mIoU: 0.0189\n",
      "Class: 16, mIoU: 0.0015\n",
      "Class: 17, mIoU: 0.0214\n",
      "Class: 18, mIoU: 0.0003\n",
      "Epoch: 47, Loss: 1.964179705619812, mIoU: 12.97%\n",
      "Class: 0, mIoU: 0.4176\n",
      "Class: 1, mIoU: 0.1603\n",
      "Class: 2, mIoU: 0.4080\n",
      "Class: 3, mIoU: 0.0158\n",
      "Class: 4, mIoU: 0.0406\n",
      "Class: 5, mIoU: 0.0552\n",
      "Class: 6, mIoU: 0.0433\n",
      "Class: 7, mIoU: 0.0002\n",
      "Class: 8, mIoU: 0.4522\n",
      "Class: 9, mIoU: 0.0233\n",
      "Class: 10, mIoU: 0.6423\n",
      "Class: 11, mIoU: 0.0463\n",
      "Class: 12, mIoU: 0.0000\n",
      "Class: 13, mIoU: 0.1431\n",
      "Class: 14, mIoU: 0.0129\n",
      "Class: 15, mIoU: 0.0016\n",
      "Class: 16, mIoU: 0.0020\n",
      "Class: 17, mIoU: 0.0000\n",
      "Class: 18, mIoU: 0.0000\n",
      "Epoch: 48, Loss: 1.0991602663993836, mIoU: 20.91%\n",
      "Class: 0, mIoU: 0.5572\n",
      "Class: 1, mIoU: 0.1347\n",
      "Class: 2, mIoU: 0.6300\n",
      "Class: 3, mIoU: 0.0546\n",
      "Class: 4, mIoU: 0.0394\n",
      "Class: 5, mIoU: 0.1300\n",
      "Class: 6, mIoU: 0.1138\n",
      "Class: 7, mIoU: 0.0331\n",
      "Class: 8, mIoU: 0.7002\n",
      "Class: 9, mIoU: 0.1591\n",
      "Class: 10, mIoU: 0.7099\n",
      "Class: 11, mIoU: 0.2578\n",
      "Class: 12, mIoU: 0.0075\n",
      "Class: 13, mIoU: 0.3675\n",
      "Class: 14, mIoU: 0.0630\n",
      "Class: 15, mIoU: 0.0126\n",
      "Class: 16, mIoU: 0.0005\n",
      "Class: 17, mIoU: 0.0003\n",
      "Class: 18, mIoU: 0.0026\n",
      "Epoch: 49, Loss: 1.032804139137268, mIoU: 21.36%\n",
      "Class: 0, mIoU: 0.6059\n",
      "Class: 1, mIoU: 0.1535\n",
      "Class: 2, mIoU: 0.6220\n",
      "Class: 3, mIoU: 0.0642\n",
      "Class: 4, mIoU: 0.0341\n",
      "Class: 5, mIoU: 0.1371\n",
      "Class: 6, mIoU: 0.1095\n",
      "Class: 7, mIoU: 0.0373\n",
      "Class: 8, mIoU: 0.7088\n",
      "Class: 9, mIoU: 0.1281\n",
      "Class: 10, mIoU: 0.7104\n",
      "Class: 11, mIoU: 0.2287\n",
      "Class: 12, mIoU: 0.0084\n",
      "Class: 13, mIoU: 0.4144\n",
      "Class: 14, mIoU: 0.0656\n",
      "Class: 15, mIoU: 0.0143\n",
      "Class: 16, mIoU: 0.0002\n",
      "Class: 17, mIoU: 0.0122\n",
      "Class: 18, mIoU: 0.0032\n",
      "Epoch: 50, Loss: 0.9282069687843323, mIoU: 23.25%\n",
      "Class: 0, mIoU: 0.6269\n",
      "Class: 1, mIoU: 0.1625\n",
      "Class: 2, mIoU: 0.6423\n",
      "Class: 3, mIoU: 0.0801\n",
      "Class: 4, mIoU: 0.0684\n",
      "Class: 5, mIoU: 0.1757\n",
      "Class: 6, mIoU: 0.1415\n",
      "Class: 7, mIoU: 0.0554\n",
      "Class: 8, mIoU: 0.7440\n",
      "Class: 9, mIoU: 0.1507\n",
      "Class: 10, mIoU: 0.7159\n",
      "Class: 11, mIoU: 0.2495\n",
      "Class: 12, mIoU: 0.0162\n",
      "Class: 13, mIoU: 0.4752\n",
      "Class: 14, mIoU: 0.0796\n",
      "Class: 15, mIoU: 0.0140\n",
      "Class: 16, mIoU: 0.0000\n",
      "Class: 17, mIoU: 0.0170\n",
      "Class: 18, mIoU: 0.0018\n",
      "[INFO] Total training time: 262886.860 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train/Batch loss</td><td>█▆▆▅▄▃▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▁▁▁▁▁▆▂▁</td></tr><tr><td>train/Epoch loss</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁</td></tr><tr><td>val/Validation loss</td><td>▄▃▁▂▅▃▃▄▁▂▁▁▂▂▂▁▂▂▇▆▄▂▆▄▄▁▂▁▁▂█▂▃▂▁▂▂▇▂▂</td></tr><tr><td>val/mIoU</td><td>▁▄▅▅▄▄▅▅▆▆▆▇▇▆▅▆▇▆▄▅▆▆▄▅▄▇▇▇█▇▂▆▆▇█▇▇▁▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>50</td></tr><tr><td>train/Batch loss</td><td>0.11292</td></tr><tr><td>train/Epoch loss</td><td>0.10308</td></tr><tr><td>val/Validation loss</td><td>0.92821</td></tr><tr><td>val/mIoU</td><td>0.23246</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">horizFlip_rc_jitter</strong> at: <a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter/runs/s0191cua' target=\"_blank\">https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter/runs/s0191cua</a><br/> View project at: <a href='https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter' target=\"_blank\">https://wandb.ai/porta-luca/bisenet_gta_horizFlip_rc_jitter</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240702_145946-s0191cua\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "#run names\n",
    "project_name = \"bisenet_gta_horizFlip_rc_jitter\"\n",
    "run_name = \"horizFlip_rc_jitter\"\n",
    "\n",
    "#start wandb run\n",
    "wandb.init(project=project_name, name=run_name, config=config)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "top_miou = 0\n",
    "\n",
    "\"\"\"\n",
    "# Setup training and save the results\n",
    "for epoch in range(config[\"max_epochs\"]):\n",
    "    wandb.log({\"Epoch\": epoch+1})\n",
    "    train(model, optimizer, train_dataloader, loss_fn)\n",
    "    avg_loss, miou, mean_iou = eval(model, val_dataloader, loss_fn, device=device)\n",
    "    if scheduler != None:\n",
    "      scheduler.step()\n",
    "    #save model state every 5 epochs\n",
    "    if(top_miou < miou):\n",
    "      torch.save(model.state_dict(), f\"./drive/MyDrive/Colab Notebooks/model_weights/{project_name}/{run_name}_epoch{epoch}.pth\")\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
    "    for i, value in enumerate(mean_iou):\n",
    "        print(f\"Class: {i}, mIoU: {value:.4f}\")\n",
    "\"\"\"\n",
    "\n",
    "# Define the subfolder name\n",
    "subfolder_name = \"model_states_horizFlip_rc_jitter\"\n",
    "\n",
    "# Create the subfolder if it doesn't exist\n",
    "os.makedirs(subfolder_name, exist_ok=True)\n",
    "\n",
    "for epoch in range(config[\"max_epochs\"]):\n",
    "    wandb.log({\"Epoch\": epoch+1})\n",
    "    train(model, optimizer, train_dataloader, loss_fn)\n",
    "    avg_loss, miou, mean_iou = eval(model, val_dataloader, loss_fn, device=device)\n",
    "    if scheduler != None:\n",
    "        scheduler.step()\n",
    "    # Save model state every 5 epochs\n",
    "    if top_miou < miou:\n",
    "        top_miou = miou\n",
    "        model_path = os.path.join(subfolder_name, f\"{project_name}_{run_name}_epoch{epoch}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
    "    for i, value in enumerate(mean_iou):\n",
    "        print(f\"Class: {i}, mIoU: {value:.4f}\")\n",
    "\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37e0ba-d904-4512-b6b4-f83381097fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
