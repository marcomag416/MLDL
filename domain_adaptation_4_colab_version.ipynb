{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcomag416/MLDL/blob/main/domain_adaptation_4_colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X2W7O-ywfU69",
      "metadata": {
        "id": "X2W7O-ywfU69"
      },
      "source": [
        "# Preliminary code\n",
        "Feel free to delete/skip this part if run in a persistent environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Svp4YfHzmnOb",
      "metadata": {
        "id": "Svp4YfHzmnOb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import sys\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7-Ci8W6afSF1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "7-Ci8W6afSF1",
        "outputId": "a1f18db1-9090-465a-fbe7-b65fc7590ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.8.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#install and import wandb for data collecting\n",
        "!pip install wandb\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "irlZ-v3zqFw6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irlZ-v3zqFw6",
        "outputId": "0bd4a0ff-8396-4a72-a877-b9123b2abe21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ],
      "source": [
        "#download and extract project repository\n",
        "\n",
        "url= \"https://github.com/marcomag416/MLDL/archive/refs/heads/main.zip\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    #print(response.content)\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('./')\n",
        "    print('Download and extraction complete!')\n",
        "\n",
        "sys.path.insert(0, './MLDL-main')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "hKBrbjoN4sOx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKBrbjoN4sOx",
        "outputId": "875157bf-916b-42fb-badf-d3efb8076b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Extracting dataset...\n"
          ]
        }
      ],
      "source": [
        "#download cityscapes dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "cityscape_dataset_path = \"./dataset/Cityscapes/Cityspaces\"\n",
        "\n",
        "#extract zip file\n",
        "if not os.path.exists(cityscape_dataset_path):\n",
        "  print(\"Extracting dataset...\")\n",
        "  with ZipFile(\"/content/drive/MyDrive/Colab Notebooks/dataset/Cityscapes.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./dataset\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fW4Y5QFOnAW5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW4Y5QFOnAW5",
        "outputId": "79b67c80-b06e-4687-9f38-e51f87a239b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "#download and index gta5 dataset\n",
        "\n",
        "gta_path = \"/content/drive/MyDrive/Colab Notebooks/dataset/GTA5.zip\"\n",
        "\n",
        "# Define paths\n",
        "gta_dataset_path = \"./dataset/\"\n",
        "images_path = gta_dataset_path + 'GTA5/images'\n",
        "labels_path = gta_dataset_path + 'GTA5/labels'\n",
        "\n",
        "#extract zip file\n",
        "if not os.path.exists(images_path):\n",
        "  print(\"Extracting dataset...\")\n",
        "  with ZipFile(gta_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gta_dataset_path)\n",
        "\n",
        "\n",
        "# Initialize lists to hold data\n",
        "data = []\n",
        "\n",
        "# Load images and corresponding masks\n",
        "for image_filename in os.listdir(images_path):\n",
        "    if image_filename.endswith('.png'):\n",
        "        image_path = os.path.join(images_path, image_filename)\n",
        "        mask_path = os.path.join(labels_path, image_filename)\n",
        "\n",
        "        # Check if corresponding mask file exists\n",
        "        if os.path.exists(mask_path):\n",
        "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                mask = Image.open(mask_path)\n",
        "\n",
        "                # Add data to list\n",
        "                data.append({\n",
        "                    'image_path': image_path,\n",
        "                    'mask_path': mask_path\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('./gta5_segmentation_dataset.csv', index=False)\n",
        "\n",
        "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4n2hNEvEfioO",
      "metadata": {
        "id": "4n2hNEvEfioO"
      },
      "source": [
        "# 4 Adversarial domain adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A4TJTbnRogKb",
      "metadata": {
        "id": "A4TJTbnRogKb"
      },
      "source": [
        "## Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6oUDR5aSmuiK",
      "metadata": {
        "id": "6oUDR5aSmuiK"
      },
      "outputs": [],
      "source": [
        "#import from packages\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import PolynomialLR\n",
        "from timeit import default_timer as timer\n",
        "from torch.autograd import Variable\n",
        "\n",
        "#other imports\n",
        "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from models.domainAdaptationModule import DomainAdaptationModule\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "M_wOtOxgoOcZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wOtOxgoOcZ",
        "outputId": "325e4683-fa53-4e7c-a85b-12736a214c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GTA_Dataset size: 2500\n"
          ]
        }
      ],
      "source": [
        "# Define the custom dataset class\n",
        "class GTASegmentationDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_mapping = self._create_label_mapping()\n",
        "        #self.color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "        #self.gaussian_blur = T.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 5))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.data_frame.iloc[idx, 0]\n",
        "        mask_name = self.data_frame.iloc[idx, 1]\n",
        "\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        mask = Image.open(mask_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        #image = self.color_jitter(image)\n",
        "        #image = self.gaussian_blur(image)\n",
        "\n",
        "        mask = self._map_mask(np.array(mask))\n",
        "\n",
        "        if self.transform:\n",
        "            # Convert mask to tensor without normalization\n",
        "            mask = torch.from_numpy(mask).permute(2, 0, 1).float()\n",
        "            mask = mask[0]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def _create_label_mapping(self):\n",
        "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
        "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
        "        return label_mapping\n",
        "\n",
        "    def _map_mask(self, mask):\n",
        "        new_mask = np.zeros_like(mask)\n",
        "        for color, label_id in self.label_mapping.items():\n",
        "            color_mask = np.all(mask == color, axis=-1)\n",
        "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
        "        return new_mask\n",
        "\n",
        "\n",
        "\n",
        "# Define paths\n",
        "csv_file = './gta5_segmentation_dataset.csv'\n",
        "\n",
        "# Define image transformations\n",
        "transform = A.Compose([\n",
        "    A.Resize(720, 1280),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    #A.RandomRotate90(),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    #A.VerticalFlip(p=0.5),\n",
        "    A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    A.GaussianBlur((3, 7), sigma_limit=(0.1, 5)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "gta_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n",
        "\n",
        "print(f\"GTA_Dataset size: {len(gta_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d9ff9f41-0185-4d9e-9a18-58439fef42bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ff9f41-0185-4d9e-9a18-58439fef42bb",
        "outputId": "1914b60a-6015-4989-9366-b6b3359e6310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cityscapes_Dataset_val size: 500\n",
            "Cityscapes_Dataset_train size: 1572\n"
          ]
        }
      ],
      "source": [
        "class Cityscapes(Dataset):\n",
        "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.label_type = label_type\n",
        "\n",
        "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
        "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.label_paths = []\n",
        "\n",
        "        # Manually iterate over directories\n",
        "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
        "        for city in cities:\n",
        "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
        "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
        "\n",
        "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
        "                continue\n",
        "\n",
        "            for img_file in os.listdir(img_dir_city):\n",
        "                if img_file.endswith('_leftImg8bit.png'):\n",
        "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
        "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
        "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
        "\n",
        "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.label_paths.append(lbl_path)\n",
        "                    else:\n",
        "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        lbl_path = self.label_paths[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = Image.open(lbl_path)\n",
        "\n",
        "        image = np.array(image)\n",
        "        label = np.array(label)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=label)\n",
        "            image, label = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_transforms = A.Compose([\n",
        "    A.Resize(512, 1024),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "train_transforms = A.Compose([\n",
        "    A.Resize(512, 1024),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    #A.VerticalFlip(p=0.5),\n",
        "    A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    A.GaussianBlur((3, 7), sigma_limit=(0.1, 5)),\n",
        "    A.Resize(720, 1280),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "city_dataset_val = Cityscapes(root_dir=cityscape_dataset_path, split='val', transforms=image_transforms)\n",
        "city_dataset_train = Cityscapes(root_dir=cityscape_dataset_path, split='train', transforms=train_transforms)\n",
        "\n",
        "\n",
        "print(f\"Cityscapes_Dataset_val size: {len(city_dataset_val)}\")\n",
        "print(f\"Cityscapes_Dataset_train size: {len(city_dataset_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-8S79esfovZ4",
      "metadata": {
        "id": "-8S79esfovZ4"
      },
      "source": [
        "## Train and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d0ed0f97-7f98-465d-9726-48c43989280f",
      "metadata": {
        "id": "d0ed0f97-7f98-465d-9726-48c43989280f"
      },
      "outputs": [],
      "source": [
        "def train_step(model, d_model1, d_model2, d_model3,\n",
        "          optimizer_model, optimizer_d1, optimizer_d2, optimizer_d3,\n",
        "          src_dataloader, trg_dataloader, loss_seg_fn, loss_bce_fn,\n",
        "          step_size,\n",
        "          lambda_seg=[1.0, 1.0, 1.0], lambda_adv=[1.0, 1.0, 1.0]):\n",
        "    # labels for adversarial training\n",
        "    source_label = 0\n",
        "    target_label = 1\n",
        "\n",
        "    discriminators = [d_model1, d_model2, d_model3]\n",
        "    disc_optimizers = [optimizer_d1, optimizer_d2, optimizer_d3]\n",
        "\n",
        "    # set the models and discriminators to training mode\n",
        "    model.train()\n",
        "    for discr in discriminators:\n",
        "      discr.train()\n",
        "\n",
        "    src_data_iter = enumerate(src_dataloader)\n",
        "    trg_data_iter = enumerate(trg_dataloader)\n",
        "\n",
        "    G_seg_loss = 0.0\n",
        "    G_adv_loss = 0.0\n",
        "    D_loss = 0.0\n",
        "\n",
        "    # reset optimizer gradients\n",
        "    optimizer_model.zero_grad()\n",
        "    for opt in disc_optimizers:\n",
        "      opt.zero_grad()\n",
        "\n",
        "    for idx in range(step_size):\n",
        "        # ---- train G ----\n",
        "\n",
        "        # disable gradient in discriminators\n",
        "        for discr in discriminators:\n",
        "          for param in discr.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # train with source\n",
        "        _, (src_input, src_labels) = next(src_data_iter)\n",
        "        src_input, src_labels = Variable(src_input).to(device), Variable(src_labels.long()).to(device)\n",
        "\n",
        "        src_preds = model(src_input)\n",
        "\n",
        "        loss_seg = 0.0\n",
        "        for lamb, pred in zip(lambda_seg, src_preds):\n",
        "          loss = loss_seg_fn(pred, src_labels)\n",
        "          loss_seg += lamb * loss\n",
        "        loss_seg = loss_seg / step_size\n",
        "\n",
        "        # train with target\n",
        "        _, (trg_input, _) = next(src_data_iter)\n",
        "        trg_input = Variable(trg_input).to(device)\n",
        "\n",
        "        trg_preds = model(trg_input)\n",
        "\n",
        "        loss_adv = 0.0\n",
        "        for discr, pred, lamd in zip(discriminators, trg_preds, lambda_adv):\n",
        "          D_out = discr(F.softmax(pred))\n",
        "          loss_d =  loss_bce_fn(D_out, Variable(torch.FloatTensor(D_out.data.size()).fill_(source_label)).to(device))\n",
        "          loss_adv += loss_d * lamb\n",
        "        loss_adv = loss_adv / step_size\n",
        "\n",
        "        # ---- train D ----\n",
        "\n",
        "        # enable gradient in discriminators\n",
        "        for discr in discriminators:\n",
        "          for param in discr.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        batch_D_loss = 0.0\n",
        "        for discr, src_pred, trg_pred in zip(discriminators, src_preds, trg_preds):\n",
        "         src_pred.detach()\n",
        "         trg_pred.detach()\n",
        "         tot_pred = torch.cat((src_pred, trg_pred), dim=0) #concatenate along batch dimension\n",
        "         D_out = discr(F.softmax(tot_pred))\n",
        "\n",
        "         src_shape = list(D_out.size())\n",
        "         src_shape[0] = src_pred.size()[0]\n",
        "         trg_shape = list(D_out.size())\n",
        "         trg_shape[0] = trg_pred.size()[0]\n",
        "\n",
        "         src_label =  Variable(torch.FloatTensor(size=src_shape).fill_(source_label)).to(device)\n",
        "         trg_label =  Variable(torch.FloatTensor(size=trg_shape).fill_(target_label)).to(device)\n",
        "         tot_label = torch.cat((src_label, trg_label), dim=0)\n",
        "\n",
        "         loss_d =  loss_bce_fn(D_out, tot_label)\n",
        "         batch_D_loss += loss_d / step_size\n",
        "\n",
        "        \"\"\"\n",
        "        # train with source\n",
        "        for pred in src_preds:\n",
        "          pred.detach()\n",
        "          print(pred.shape)\n",
        "\n",
        "        losses = [loss_seg, loss_adv]\n",
        "        for discr, pred in zip(discriminators, src_preds):\n",
        "          D_out = discr(F.softmax(pred))\n",
        "          print(D_out.shape)\n",
        "          loss_d =  loss_bce_fn(D_out, Variable(torch.FloatTensor(D_out.data.size()).fill_(source_label)).to(device))\n",
        "          loss_d = loss_d / epoch_size / 2\n",
        "          losses.append(loss_d)\n",
        "          batch_D_loss += loss_d\n",
        "\n",
        "        # train with target\n",
        "        for pred in trg_preds:\n",
        "          pred.detach()\n",
        "          print(pred.shape)\n",
        "\n",
        "        for discr, pred in zip(discriminators, trg_preds):\n",
        "          pred.detach()\n",
        "          D_out = discr(F.softmax(pred))\n",
        "          print(D_out.shape)\n",
        "          loss_d =  loss_bce_fn(D_out, Variable(torch.FloatTensor(D_out.data.size()).fill_(target_label)).to(device))\n",
        "          loss_d = loss_d / epoch_size / 2\n",
        "          losses.append(loss_d)\n",
        "          batch_D_loss += loss_d\n",
        "        \"\"\"\n",
        "\n",
        "        torch.autograd.backward([loss_seg, loss_adv, batch_D_loss])\n",
        "\n",
        "        #wandb.log({\"train G/Batch segmentation loss\": loss_seg, \"train G/Batch adversarial loss\": loss_adv, \"train D/Batch loss\": batch_D_loss})\n",
        "        D_loss += batch_D_loss\n",
        "        G_adv_loss += loss_adv\n",
        "        G_seg_loss += loss_seg\n",
        "\n",
        "    #optimizers steps\n",
        "    optimizer_model.step()\n",
        "    for opt in disc_optimizers:\n",
        "      opt.step()\n",
        "\n",
        "    wandb.log({\"train G/Step segmentation loss\": G_seg_loss, \"train G/Step adversarial loss\": G_adv_loss, \"train D/Step loss\": D_loss}, commit=False)\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "def compute_iou(pred, target, num_classes):\n",
        "    ious = []\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = (pred == cls)\n",
        "        target_inds = (target == cls)\n",
        "        intersection = (pred_inds[target_inds]).sum().item()\n",
        "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "\n",
        "    return np.array(ious)\n",
        "\n",
        "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    total = 0\n",
        "    all_ious = []  # List to store IoUs for each batch\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for inputs_test, targets_test in dataloader:\n",
        "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_test = model(inputs_test)  # Forward pass\n",
        "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
        "\n",
        "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
        "            _, predicted_test = outputs_test.max(1)\n",
        "            total += targets_test.size(0)\n",
        "\n",
        "            # Compute IoU for this batch\n",
        "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = test_loss / total\n",
        "\n",
        "    # Calculate mean IoU\n",
        "    all_ious = np.array(all_ious)\n",
        "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
        "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
        "\n",
        "    wandb.log({\"val/Validation loss\": avg_loss, \"val/mIoU\": miou}, commit=False)\n",
        "\n",
        "    return avg_loss, miou, mean_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n7pVxXwRo2kZ",
      "metadata": {
        "id": "n7pVxXwRo2kZ"
      },
      "source": [
        "## Experiment set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d68301fd-48a9-43f7-8749-f3ef6974be40",
      "metadata": {
        "id": "d68301fd-48a9-43f7-8749-f3ef6974be40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36218b63-f9f1-418b-9a79-66c00dfb94be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "\n",
        "context_path = 'resnet18'\n",
        "\n",
        "#save hyperparameters\n",
        "config = {\n",
        "    \"learning_rate_G\": 2.5e-2,\n",
        "    \"momentum_G\": 0.9,\n",
        "    \"weight_decay_G\": 1e-4,\n",
        "    \"learning_rate_D\": 2.5e-4,\n",
        "    \"num_steps\": int(1e4),\n",
        "    \"step_size\": 4,\n",
        "    \"batch_size\": 2,\n",
        "    \"validation_period\": 200,\n",
        "    \"lambda_seg\": [1.0, 0.1, 0.01],\n",
        "    \"lambda_adv\": [1e-3, 2e-4, 4e-5],\n",
        "    \"target dataset\": \"Cityscapes\",\n",
        "    \"source dataset\": \"GTA\",\n",
        "    \"scheduler\": \"None\",\n",
        "    \"scheduler_poly_power\": 0.9,\n",
        "    \"optimizer D\": \"Adam\",\n",
        "    \"optimizer G\": \"SGD\",\n",
        "    \"transformations\": \"Gaussian blur, random crop, horFlip, colorJitter\",\n",
        "    \"pretrained weights\": True\n",
        "}\n",
        "\n",
        "\n",
        "# create dataloaders\n",
        "gta_dataloader = DataLoader(gta_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4)\n",
        "city_dataloader_val = DataLoader(city_dataset_val, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "city_dataloader_train = DataLoader(city_dataset_train, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4)\n",
        "\n",
        "# Initialize the model\n",
        "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
        "d_model1 = DomainAdaptationModule(num_classes = 19).to(device)\n",
        "d_model2 = DomainAdaptationModule(num_classes = 19).to(device)\n",
        "d_model3 = DomainAdaptationModule(num_classes = 19).to(device)\n",
        "\n",
        "seg_loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
        "bce_loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate_G\"], momentum=config[\"momentum_G\"], weight_decay=config[\"weight_decay_G\"])\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate_G\"])\n",
        "optimizer_d1 = torch.optim.Adam(d_model1.parameters(), lr=config[\"learning_rate_D\"], betas=(0.9, 0.99))\n",
        "optimizer_d2 = torch.optim.Adam(d_model2.parameters(), lr=config[\"learning_rate_D\"], betas=(0.9, 0.99))\n",
        "optimizer_d3 = torch.optim.Adam(d_model3.parameters(), lr=config[\"learning_rate_D\"], betas=(0.9, 0.99))\n",
        "\n",
        "#scheduler_g = PolynomialLR(optimizer, total_iters=config[\"num_steps\"], power=config[\"scheduler_poly_power\"])\n",
        "#scheduler_d1 = PolynomialLR(optimizer_d1, total_iters=config[\"num_steps\"], power=config[\"scheduler_poly_power\"])\n",
        "#scheduler_d2 = PolynomialLR(optimizer_d2, total_iters=config[\"num_steps\"], power=config[\"scheduler_poly_power\"])\n",
        "#scheduler_d3 = PolynomialLR(optimizer_d3, total_iters=config[\"num_steps\"], power=config[\"scheduler_poly_power\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "D_Otmc0e9BFr",
      "metadata": {
        "id": "D_Otmc0e9BFr"
      },
      "outputs": [],
      "source": [
        "#run names\n",
        "project_name = \"domain_adaptation_right\"\n",
        "run_name = \"pretrained19_no_scheduler\"\n",
        "run_id = \"\"\n",
        "\n",
        "#set epoch to 0 to start training from scratch\n",
        "load_step = 0\n",
        "\n",
        "#path for loading/saving model weight\n",
        "weight_dir = f\"./drive/MyDrive/Colab Notebooks/model_weights/{project_name}\"\n",
        "load_weight_path = weight_dir + f\"/{run_name}_step{load_step}.pth\"\n",
        "\n",
        "resume = \"never\"\n",
        "id = None\n",
        "if(load_step > 0):\n",
        "  resume=\"must\"\n",
        "  model.load_state_dict(torch.load(load_weight_path))\n",
        "  #optimizer.load_state_dict(torch.load(state_path))\n",
        "  id = run_id\n",
        "  load_step += 1 #start training from next step\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "AvTga9lvE2kt",
      "metadata": {
        "id": "AvTga9lvE2kt"
      },
      "outputs": [],
      "source": [
        "pretrained_weights_path = \"./drive/MyDrive/Colab Notebooks/model_weights/bisenet_gta/gaussian_jitter_epoch19.pth\"\n",
        "if config[\"pretrained weights\"] and pretrained_weights_path:\n",
        "  model.load_state_dict(torch.load(pretrained_weights_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HNVBdCoCo76a",
      "metadata": {
        "id": "HNVBdCoCo76a"
      },
      "source": [
        "## Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3387c21-5c4e-4de8-9fe4-62c8fa5cac85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "b3387c21-5c4e-4de8-9fe4-62c8fa5cac85",
        "outputId": "2be74133-6cef-4720-dfe8-056bba1214d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcomag416\u001b[0m (\u001b[33mmarco-magnanini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240708_145419-02a42ahp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marco-magnanini/domain_adaptation_right/runs/02a42ahp' target=\"_blank\">pretrained19_no_scheduler</a></strong> to <a href='https://wandb.ai/marco-magnanini/domain_adaptation_right' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/marco-magnanini/domain_adaptation_right' target=\"_blank\">https://wandb.ai/marco-magnanini/domain_adaptation_right</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/marco-magnanini/domain_adaptation_right/runs/02a42ahp' target=\"_blank\">https://wandb.ai/marco-magnanini/domain_adaptation_right/runs/02a42ahp</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#create path for model weights\n",
        "if not os.path.exists(weight_dir):\n",
        "        os.makedirs(weight_dir)\n",
        "\n",
        "#start wandb run\n",
        "wandb.init(id=id, project=project_name, name=run_name, config=config, resume=resume)\n",
        "\n",
        "best_mIoU = 0.0\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "for step in range(load_step, config[\"num_steps\"]):\n",
        "    wandb.log({\"Step\": step}, commit=False)\n",
        "    train_step(model, d_model1, d_model2, d_model3, optimizer_model=optimizer, optimizer_d1=optimizer_d1, optimizer_d2=optimizer_d2, optimizer_d3=optimizer_d3, src_dataloader=gta_dataloader, trg_dataloader=city_dataloader_val, loss_seg_fn=seg_loss_fn, loss_bce_fn=bce_loss_fn, step_size=config[\"step_size\"], lambda_seg=config[\"lambda_seg\"], lambda_adv=config[\"lambda_adv\"])\n",
        "\n",
        "    if config[\"scheduler\"] != \"None\":\n",
        "      scheduler_g.step()\n",
        "      scheduler_d1.step()\n",
        "      scheduler_d2.step()\n",
        "      scheduler_d3.step()\n",
        "\n",
        "    #validate model every validation period\n",
        "    if((step+1) % config[\"validation_period\"] == 0):\n",
        "      avg_loss, miou, IoUs = eval(model, city_dataloader_val, seg_loss_fn, device=device)\n",
        "      print(f\"Step: {step}, Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
        "      print(f\"\\t IoU per class: {IoUs}\")\n",
        "      if(miou > best_mIoU and (step + 1) > (2* config[\"validation_period\"])):\n",
        "        file_name = f\"/{run_name}_step{step}.pth\"\n",
        "        torch.save(model.state_dict(), weight_dir + file_name)\n",
        "        best_mIoU = miou\n",
        "        print(\"Model weights saved as: \"+ file_name)\n",
        "\n",
        "    wandb.log({}, commit=True)\n",
        "\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_MzB_5wQxvY1",
      "metadata": {
        "id": "_MzB_5wQxvY1"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}