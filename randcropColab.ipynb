{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcomag416/MLDL/blob/main/randcropColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xczxMn5qsO1F"
      },
      "source": [
        "# Download GTA 5 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2fUDNH1LWZBg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "\n",
        "gta_path = \"/content/drive/MyDrive/GTA5.zip\"\n",
        "\n",
        "gta_dataset_path = \"./dataset/\"\n",
        "\n",
        "#extract zip file\n",
        "with ZipFile(gta_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gta_dataset_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTquAANUsTFb"
      },
      "source": [
        "#download cityscapes dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7GiDWt0ShSV-"
      },
      "outputs": [],
      "source": [
        "with ZipFile(\"/content/drive/MyDrive/Cityscapes.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./dataset\")\n",
        "\n",
        "cityscape_dataset_path = \"./dataset/Cityscapes/Cityspaces\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewdC581XsZjV"
      },
      "source": [
        "# Creating semantic segmented dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS34dnRuW2pc",
        "outputId": "e4234870-f512-407b-d50e-a06991c50cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define paths\n",
        "images_path = gta_dataset_path + 'GTA5/images'\n",
        "labels_path = gta_dataset_path + 'GTA5/labels'\n",
        "\n",
        "# Initialize lists to hold data\n",
        "data = []\n",
        "\n",
        "# Load images and corresponding masks\n",
        "for image_filename in os.listdir(images_path):\n",
        "    if image_filename.endswith('.png'):\n",
        "        image_path = os.path.join(images_path, image_filename)\n",
        "        mask_path = os.path.join(labels_path, image_filename)\n",
        "\n",
        "        # Check if corresponding mask file exists\n",
        "        if os.path.exists(mask_path):\n",
        "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                mask = Image.open(mask_path)\n",
        "\n",
        "                # Add data to list\n",
        "                data.append({\n",
        "                    'image_path': image_path,\n",
        "                    'mask_path': mask_path\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('gta5_segmentation_dataset.csv', index=False)\n",
        "\n",
        "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQVP5gXJyA7W",
        "outputId": "7ef6ed79-3709-47e3-c228-d220a34cf1ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wandb"
      ],
      "metadata": {
        "id": "8203Tz05Ox-n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "o5SZkc_9W9nr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "88d78a9c-3a55-468a-aa0d-b1a0e0c21c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.17.2-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/6.9 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/6.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m6.2/6.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.6.0-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.6.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#install and import wandb for data collecting\n",
        "!pip install wandb\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7x3SK1_soei"
      },
      "source": [
        "# Download pytorchdl_gta5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvwLZovyr49X"
      },
      "source": [
        "One of these 2 ways should work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv1UYSPfr8HV"
      },
      "source": [
        "1. download directly from github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIpykOwLq_qW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d798512c-bcdd-4aa2-bf55-a3d86a0984ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Define the repository URL and destination path\n",
        "repository_url = \"https://github.com/marcomag416/MLDL/tree/main/pytorchdl_gta5\"\n",
        "destination_path = \"./\"\n",
        "\n",
        "# Clone the GitHub repository\n",
        "subprocess.call([\"git\", \"clone\", repository_url, destination_path])\n",
        "\n",
        "print(\"Folder downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Z0B6GPr-KU"
      },
      "source": [
        "2. upload the zip file manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NhYtC583gkbf"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "file_path = \"/pytorchdl_gta5.zip\"\n",
        "\n",
        "# Specify the destination directory for unzipping\n",
        "destination_path = \"/content/pytorchdl_gta5\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UavN0os5gkej"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nWdib__ttqM"
      },
      "source": [
        "# Transformation and preparing train loader with GTA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IGWmPz6hW9vF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "if __name__ != '__main__':\n",
        "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define the custom dataset class\n",
        "class GTASegmentationDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_mapping = self._create_label_mapping()\n",
        "        self.color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "        self.gaussian_blur = T.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 5))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.data_frame.iloc[idx, 0]\n",
        "        mask_name = self.data_frame.iloc[idx, 1]\n",
        "\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        mask = Image.open(mask_name).convert('RGB')\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "\n",
        "        image = self.gaussian_blur(image)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        mask = self._map_mask(np.array(mask))\n",
        "\n",
        "        # Convert mask to tensor without normalization\n",
        "        mask = torch.from_numpy(mask).long()  # Ensure the mask is of type long for cross-entropy loss\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def _create_label_mapping(self):\n",
        "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
        "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
        "        return label_mapping\n",
        "\n",
        "    def _map_mask(self, mask):\n",
        "        new_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
        "        for color, label_id in self.label_mapping.items():\n",
        "            color_mask = np.all(mask == color, axis=-1)\n",
        "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
        "        return new_mask\n",
        "\n",
        "# Define paths\n",
        "csv_file = 'gta5_segmentation_dataset.csv'\n",
        "\n",
        "# Define image transformations\n",
        "transform = A.Compose([\n",
        "    A.Resize(720, 1280),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    A.RandomRotate90(),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_wPbXy7XFd8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0ouzhUBXFgb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjEYDBIFXFit"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhLuCUYMuAWI"
      },
      "source": [
        "# Transformation and preparing val loader with cityscape dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmtB6CQ0W9x2",
        "outputId": "dd0d01c3-64af-4b4d-d63a-99d260123566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_Dataset size: 500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "\n",
        "class Cityscapes(Dataset):\n",
        "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.label_type = label_type\n",
        "\n",
        "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
        "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.label_paths = []\n",
        "\n",
        "        # Manually iterate over directories\n",
        "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
        "        for city in cities:\n",
        "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
        "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
        "\n",
        "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
        "                continue\n",
        "\n",
        "            for img_file in os.listdir(img_dir_city):\n",
        "                if img_file.endswith('_leftImg8bit.png'):\n",
        "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
        "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
        "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
        "\n",
        "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.label_paths.append(lbl_path)\n",
        "                    else:\n",
        "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        lbl_path = self.label_paths[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = Image.open(lbl_path)\n",
        "\n",
        "        image = np.array(image)\n",
        "        label = np.array(label)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=label)\n",
        "            image, label = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_transforms = A.Compose([\n",
        "    A.Resize(512, 1024),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_dataset = Cityscapes(root_dir=cityscape_dataset_path, split='val', transforms=image_transforms)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "print(f\"Val_Dataset size: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFfRO8QNXG31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhkydhzmXHCA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6M8dlxxuFHk"
      },
      "source": [
        "# Download biseNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNa2tBxXHEY",
        "outputId": "d0069d89-1209-4c96-b653-285b3cdb38d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "model_url = \"https://github.com/ooooverflow/BiSeNet/archive/refs/heads/master.zip\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(model_url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    #print(response.content)\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('./')\n",
        "    print('Download and extraction complete!')\n",
        "\n",
        "sys.path.insert(0, './BiSeNet-master')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ddsQrYwXHGe",
        "outputId": "ffefad4c-7f8c-40c3-ac54-f97bd0302c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 144MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 153MB/s]\n"
          ]
        }
      ],
      "source": [
        "from model.build_BiSeNet import BiSeNet\n",
        "from torch import nn\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "\n",
        "context_path = 'resnet18'\n",
        "\n",
        "#save hyperparameters\n",
        "config = {\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"max_epochs\": 50,\n",
        "    \"batch_size\": 8,\n",
        "    \"weight_decay\": \"None\",\n",
        "    \"dataset\": \"Cityscapes\",\n",
        "    \"scheduler\": \"None\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"transformations\": \"random crop\"\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "scheduler = None\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_BrOkEhXOix"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLfH5zsvXOuE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZP3IMXkuM6f"
      },
      "source": [
        "# Train and evaluation func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Moi5XOZXO5u"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
        "        inputs_train = inputs_train.to(device)\n",
        "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
        "\n",
        "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
        "        outputs_train, cx1_sup, cx2_sup = model(inputs_train)  # Forward pass\n",
        "        # print(outputs_train.shape, targets_train.shape)\n",
        "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
        "\n",
        "        aux_loss1 = loss_fn_train(cx1_sup, targets_train)\n",
        "        aux_loss2 = loss_fn_train(cx2_sup, targets_train)\n",
        "\n",
        "        loss = loss + aux_loss1 + aux_loss2\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer_train.step()  # Update the weights\n",
        "\n",
        "        wandb.log({\"train/Batch loss\": loss})\n",
        "\n",
        "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
        "        _, predicted_train = outputs_train.max(1)\n",
        "        total += targets_train.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = train_loss / total\n",
        "\n",
        "    wandb.log({\"train/Epoch loss\": avg_loss})\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def compute_iou(pred, target, num_classes):\n",
        "    ious = []\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = (pred == cls)\n",
        "        target_inds = (target == cls)\n",
        "        intersection = (pred_inds[target_inds]).sum().item()\n",
        "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "\n",
        "    return np.array(ious)\n",
        "\n",
        "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    total = 0\n",
        "    all_ious = []  # List to store IoUs for each batch\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for inputs_test, targets_test in dataloader:\n",
        "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_test = model(inputs_test)  # Forward pass\n",
        "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
        "\n",
        "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
        "            _, predicted_test = outputs_test.max(1)\n",
        "            total += targets_test.size(0)\n",
        "\n",
        "            # Compute IoU for this batch\n",
        "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = test_loss / total\n",
        "\n",
        "    wandb.log({})\n",
        "\n",
        "    # Calculate mean IoU\n",
        "    all_ious = np.array(all_ious)\n",
        "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
        "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
        "\n",
        "    wandb.log({\"val/Validation loss\": avg_loss, \"val/mIoU\": miou})\n",
        "\n",
        "    return avg_loss, miou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eA5PSPNXXSPr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDW2e7i_XSSC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7-XpBZSuXuU"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "OLtp1I10XST7",
        "outputId": "96e32499-06fd-4c59-eecc-08a2c58fe6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkharazmireyhaneh25\u001b[0m (\u001b[33mmldlteam\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240624_103545-z3fde9vq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlteam/gta_cityscape/runs/z3fde9vq' target=\"_blank\">random_crop</a></strong> to <a href='https://wandb.ai/mldlteam/gta_cityscape' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlteam/gta_cityscape' target=\"_blank\">https://wandb.ai/mldlteam/gta_cityscape</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlteam/gta_cityscape/runs/z3fde9vq' target=\"_blank\">https://wandb.ai/mldlteam/gta_cityscape/runs/z3fde9vq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.9686257467269898, mIoU: 16.33%\n",
            "Epoch: 2, Loss: 0.915336309671402, mIoU: 16.39%\n",
            "Epoch: 3, Loss: 1.3382987225055694, mIoU: 13.24%\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "#run names\n",
        "project_name = \"gta_cityscape\"\n",
        "run_name = \"random_crop\"\n",
        "\n",
        "#start wandb run\n",
        "wandb.init(project=project_name, name=run_name, config=config)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "for epoch in range(config[\"max_epochs\"]):\n",
        "    wandb.log({\"Epoch\": epoch+1})\n",
        "    train(model, optimizer, train_dataloader, loss_fn)\n",
        "    avg_loss, miou = eval(model, val_dataloader, loss_fn, device=device)\n",
        "    if scheduler != None:\n",
        "      scheduler.step()\n",
        "    #save model state every 5 epochs\n",
        "    if((epoch + 1) % 5 == 0):\n",
        "      torch.save(model.state_dict(), f\"./drive/MyDrive/Colab Notebooks/model_weights/{project_name}/{run_name}_epoch{epoch}.pth\")\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "xczxMn5qsO1F"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}