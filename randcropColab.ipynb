{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1wyopcUgcZmHu7vnMFQTspBLjAyLHGRpS",
      "authorship_tag": "ABX9TyNVvZyzh6nGcWYb218pWJFt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcomag416/MLDL/blob/main/randcropColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download GTA 5 dataset"
      ],
      "metadata": {
        "id": "xczxMn5qsO1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from zipfile import ZipFile\n",
        "\n",
        "gta_path = \"/content/drive/MyDrive/MLDL-Proj/GTA5.zip\"\n",
        "\n",
        "gta_dataset_path = \"./dataset/\"\n",
        "\n",
        "#extract zip file\n",
        "with ZipFile(gta_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gta_dataset_path)\n"
      ],
      "metadata": {
        "id": "2fUDNH1LWZBg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#download cityscapes dataset"
      ],
      "metadata": {
        "id": "zTquAANUsTFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with ZipFile(\"/content/drive/MyDrive/MLDL-Proj/Cityscapes.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./dataset\")\n",
        "\n",
        "cityscape_dataset_path = \"./dataset/Cityscapes/Cityspaces\""
      ],
      "metadata": {
        "id": "7GiDWt0ShSV-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating semantic segmented dataset"
      ],
      "metadata": {
        "id": "ewdC581XsZjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS34dnRuW2pc",
        "outputId": "eb6226f3-5bfa-487f-ac92-80343a05263d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Define paths\n",
        "images_path = gta_dataset_path + 'GTA5/images'\n",
        "labels_path = gta_dataset_path + 'GTA5/labels'\n",
        "\n",
        "# Initialize lists to hold data\n",
        "data = []\n",
        "\n",
        "# Load images and corresponding masks\n",
        "for image_filename in os.listdir(images_path):\n",
        "    if image_filename.endswith('.png'):\n",
        "        image_path = os.path.join(images_path, image_filename)\n",
        "        mask_path = os.path.join(labels_path, image_filename)\n",
        "\n",
        "        # Check if corresponding mask file exists\n",
        "        if os.path.exists(mask_path):\n",
        "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                mask = Image.open(mask_path)\n",
        "\n",
        "                # Add data to list\n",
        "                data.append({\n",
        "                    'image_path': image_path,\n",
        "                    'mask_path': mask_path\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('gta5_segmentation_dataset.csv', index=False)\n",
        "\n",
        "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5SZkc_9W9nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pytorchdl_gta5"
      ],
      "metadata": {
        "id": "L7x3SK1_soei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of these 2 ways should work"
      ],
      "metadata": {
        "id": "IvwLZovyr49X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. download directly from github"
      ],
      "metadata": {
        "id": "Sv1UYSPfr8HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Define the repository URL and destination path\n",
        "repository_url = \"https://github.com/marcomag416/MLDL/tree/main/pytorchdl_gta5\"\n",
        "destination_path = \"./\"\n",
        "\n",
        "# Clone the GitHub repository\n",
        "subprocess.call([\"git\", \"clone\", repository_url, destination_path])\n",
        "\n",
        "print(\"Folder downloaded successfully!\")"
      ],
      "metadata": {
        "id": "MIpykOwLq_qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. upload the zip file manually"
      ],
      "metadata": {
        "id": "70Z0B6GPr-KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Specify the path to the zip file\n",
        "file_path = \"/content/pytorchdl_gta5.zip\"\n",
        "\n",
        "# Specify the destination directory for unzipping\n",
        "destination_path = \"/content/pytorchdl_gta5\"\n",
        "\n",
        "# Extract the contents of the zip file\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)"
      ],
      "metadata": {
        "id": "NhYtC583gkbf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UavN0os5gkej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation and preparing train loader with GTA dataset"
      ],
      "metadata": {
        "id": "4nWdib__ttqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "if __name__ != '__main__':\n",
        "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define the custom dataset class\n",
        "class GTASegmentationDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_mapping = self._create_label_mapping()\n",
        "        self.color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "        self.gaussian_blur = T.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 5))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.data_frame.iloc[idx, 0]\n",
        "        mask_name = self.data_frame.iloc[idx, 1]\n",
        "\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        mask = Image.open(mask_name).convert('RGB')\n",
        "\n",
        "        image = self.color_jitter(image)\n",
        "\n",
        "        image = self.gaussian_blur(image)\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        mask = self._map_mask(np.array(mask))\n",
        "\n",
        "        # Convert mask to tensor without normalization\n",
        "        mask = torch.from_numpy(mask).long()  # Ensure the mask is of type long for cross-entropy loss\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def _create_label_mapping(self):\n",
        "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
        "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
        "        return label_mapping\n",
        "\n",
        "    def _map_mask(self, mask):\n",
        "        new_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
        "        for color, label_id in self.label_mapping.items():\n",
        "            color_mask = np.all(mask == color, axis=-1)\n",
        "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
        "        return new_mask\n",
        "\n",
        "# Define paths\n",
        "csv_file = 'gta5_segmentation_dataset.csv'\n",
        "\n",
        "# Define image transformations\n",
        "transform = A.Compose([\n",
        "    A.Resize(720, 1280),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    A.RandomRotate90(),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "IGWmPz6hW9vF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_wPbXy7XFd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0ouzhUBXFgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FjEYDBIFXFit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation and preparing val loader with cityscape dataset"
      ],
      "metadata": {
        "id": "lhLuCUYMuAWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "\n",
        "class Cityscapes(Dataset):\n",
        "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.label_type = label_type\n",
        "\n",
        "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
        "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.label_paths = []\n",
        "\n",
        "        # Manually iterate over directories\n",
        "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
        "        for city in cities:\n",
        "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
        "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
        "\n",
        "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
        "                continue\n",
        "\n",
        "            for img_file in os.listdir(img_dir_city):\n",
        "                if img_file.endswith('_leftImg8bit.png'):\n",
        "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
        "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
        "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
        "\n",
        "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.label_paths.append(lbl_path)\n",
        "                    else:\n",
        "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        lbl_path = self.label_paths[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = Image.open(lbl_path)\n",
        "\n",
        "        image = np.array(image)\n",
        "        label = np.array(label)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=label)\n",
        "            image, label = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_transforms = A.Compose([\n",
        "    A.Resize(512, 1024),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_dataset = Cityscapes(root_dir=cityscape_dataset_path, split='val', transforms=image_transforms)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "print(f\"Val_Dataset size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmtB6CQ0W9x2",
        "outputId": "442d9cb8-7a2a-4c12-a76a-6bcaa6d5c861"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_Dataset size: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFfRO8QNXG31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhkydhzmXHCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download biseNet model"
      ],
      "metadata": {
        "id": "O6M8dlxxuFHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "model_url = \"https://github.com/ooooverflow/BiSeNet/archive/refs/heads/master.zip\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(model_url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    #print(response.content)\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('./')\n",
        "    print('Download and extraction complete!')\n",
        "\n",
        "sys.path.insert(0, './BiSeNet-master')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqNa2tBxXHEY",
        "outputId": "981734a9-bd89-43bd-f651-9bb1240be5d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PDIEV4JzpMqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxhupLV0pMwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.build_BiSeNet import BiSeNet\n",
        "from torch import nn\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "\n",
        "context_path = 'resnet18'\n",
        "\n",
        "# Initialize the model\n",
        "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ddsQrYwXHGe",
        "outputId": "88630d83-2d9f-48ac-c857-6c0b96032b6a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 115MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 167MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I_BrOkEhXOix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLfH5zsvXOuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluation func"
      ],
      "metadata": {
        "id": "lZP3IMXkuM6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
        "        inputs_train = inputs_train.to(device)\n",
        "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
        "\n",
        "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
        "        outputs_train, cx1_sup, cx2_sup = model(inputs_train)  # Forward pass\n",
        "        # print(outputs_train.shape, targets_train.shape)\n",
        "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
        "\n",
        "        aux_loss1 = loss_fn_train(cx1_sup, targets_train)\n",
        "        aux_loss2 = loss_fn_train(cx2_sup, targets_train)\n",
        "\n",
        "        loss = loss + aux_loss1 + aux_loss2\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer_train.step()  # Update the weights\n",
        "\n",
        "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
        "        _, predicted_train = outputs_train.max(1)\n",
        "        total += targets_train.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = train_loss / total\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def compute_iou(pred, target, num_classes):\n",
        "    ious = []\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = (pred == cls)\n",
        "        target_inds = (target == cls)\n",
        "        intersection = (pred_inds[target_inds]).sum().item()\n",
        "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "\n",
        "    return np.array(ious)\n",
        "\n",
        "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    total = 0\n",
        "    all_ious = []  # List to store IoUs for each batch\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for inputs_test, targets_test in dataloader:\n",
        "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_test = model(inputs_test)  # Forward pass\n",
        "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
        "\n",
        "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
        "            _, predicted_test = outputs_test.max(1)\n",
        "            total += targets_test.size(0)\n",
        "\n",
        "            # Compute IoU for this batch\n",
        "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = test_loss / total\n",
        "\n",
        "    # Calculate mean IoU\n",
        "    all_ious = np.array(all_ious)\n",
        "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
        "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
        "\n",
        "    return avg_loss, miou"
      ],
      "metadata": {
        "id": "9Moi5XOZXO5u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eA5PSPNXXSPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDW2e7i_XSSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "a7-XpBZSuXuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "for _ in range(50):\n",
        "    train(model, optimizer, train_dataloader, loss_fn)\n",
        "    avg_loss, miou = eval(model, val_dataloader, loss_fn, device=device)\n",
        "    print(f\"Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "OLtp1I10XST7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}