{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6be309-74df-4b2a-ba3d-fc1d26aef3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "images_path = 'GTA5/GTA5/images'\n",
    "labels_path = 'GTA5/GTA5/labels'\n",
    "\n",
    "# Initialize lists to hold data\n",
    "data = []\n",
    "\n",
    "# Load images and corresponding masks\n",
    "for image_filename in os.listdir(images_path):\n",
    "    if image_filename.endswith('.png'):\n",
    "        image_path = os.path.join(images_path, image_filename)\n",
    "        mask_path = os.path.join(labels_path, image_filename)\n",
    "        \n",
    "        # Check if corresponding mask file exists\n",
    "        if os.path.exists(mask_path):\n",
    "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
    "            try:\n",
    "                image = Image.open(image_path)\n",
    "                mask = Image.open(mask_path)\n",
    "                \n",
    "                # Add data to list\n",
    "                data.append({\n",
    "                    'image_path': image_path,\n",
    "                    'mask_path': mask_path\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
    "\n",
    "# Create a DataFrame from the data list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('gta5_segmentation_dataset.csv', index=False)\n",
    "\n",
    "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1126f400-c92b-49e5-a0f5-a120e006da26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.8 (you have 1.4.7). Upgrade using: pip install --upgrade albumentations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport pandas as pd\\nfrom PIL import Image\\nimport numpy as np\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom torchvision import transforms\\nfrom pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\\nimport albumentations as A\\nfrom albumentations.pytorch import ToTensorV2\\n\\nif __name__ != \\'__main__\\':\\n    raise Exception(\"This script should not be imported; it should be run directly.\")\\n\\n# Setup device agnostic code\\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\n\\n# Define the custom dataset class\\nclass GTASegmentationDataset(Dataset):\\n    def __init__(self, csv_file, transform=None):\\n        self.data_frame = pd.read_csv(csv_file)\\n        self.transform = transform\\n        self.label_mapping = self._create_label_mapping()\\n\\n    def __len__(self):\\n        return len(self.data_frame)\\n\\n    def __getitem__(self, idx):\\n        if torch.is_tensor(idx):\\n            idx = idx.tolist()\\n    \\n        img_name = self.data_frame.iloc[idx, 0]\\n        mask_name = self.data_frame.iloc[idx, 1]\\n    \\n        image = Image.open(img_name).convert(\\'RGB\\')\\n        mask = Image.open(mask_name).convert(\\'RGB\\')\\n        \\n        if self.transform:\\n            augmented = self.transform(image=np.array(image), mask=np.array(mask))\\n            image, mask = augmented[\\'image\\'], augmented[\\'mask\\']\\n            \\n        mask = self._map_mask(np.array(mask))\\n    \\n        # Convert mask to tensor without normalization\\n        mask = torch.from_numpy(mask).long()  # Ensure the mask is of type long for cross-entropy loss\\n    \\n        return image, mask\\n\\n    def _create_label_mapping(self):\\n        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\\n        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to \\'unlabeled\\'\\n        return label_mapping\\n        \\n    def _map_mask(self, mask):\\n        new_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\\n        for color, label_id in self.label_mapping.items():\\n            color_mask = np.all(mask == color, axis=-1)\\n            new_mask[color_mask] = label_id  # Use label_id instead of color\\n        return new_mask\\n\\n# Define paths\\ncsv_file = \\'gta5_segmentation_dataset.csv\\'\\n\\n# Define image transformations\\ntransform = A.Compose([\\n    A.Resize(512, 1024),\\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\\n    A.RandomRotate90(),\\n    A.RandomResizedCrop(height=512, width=1024, scale=(0.8, 1.0)),\\n    ToTensorV2()\\n])\\n\\n# Create the dataset and dataloader\\ntrain_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\\ntrain_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "if __name__ != '__main__':\n",
    "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the custom dataset class\n",
    "class GTASegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_mapping = self._create_label_mapping()\n",
    "        self.color_jitter = T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
    "        self.gaussian_blur = T.GaussianBlur(kernel_size=(3, 7), sigma=(0.1, 5))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "    \n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        mask_name = self.data_frame.iloc[idx, 1]\n",
    "    \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('RGB')\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "\n",
    "        image = self.gaussian_blur(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "            \n",
    "        mask = self._map_mask(np.array(mask))\n",
    "    \n",
    "        # Convert mask to tensor without normalization\n",
    "        mask = torch.from_numpy(mask).long()  # Ensure the mask is of type long for cross-entropy loss\n",
    "    \n",
    "        return image, mask\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
    "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
    "        return label_mapping\n",
    "        \n",
    "    def _map_mask(self, mask):\n",
    "        new_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "        for color, label_id in self.label_mapping.items():\n",
    "            color_mask = np.all(mask == color, axis=-1)\n",
    "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
    "        return new_mask\n",
    "\n",
    "# Define paths\n",
    "csv_file = 'gta5_segmentation_dataset.csv'\n",
    "\n",
    "# Define image transformations\n",
    "transform = A.Compose([\n",
    "    A.Resize(720, 1280),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomResizedCrop(height=720, width=1280, scale=(0.8, 1.0)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "if __name__ != '__main__':\n",
    "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Define the custom dataset class\n",
    "class GTASegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_mapping = self._create_label_mapping()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "    \n",
    "        img_name = self.data_frame.iloc[idx, 0]\n",
    "        mask_name = self.data_frame.iloc[idx, 1]\n",
    "    \n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "            \n",
    "        mask = self._map_mask(np.array(mask))\n",
    "    \n",
    "        # Convert mask to tensor without normalization\n",
    "        mask = torch.from_numpy(mask).long()  # Ensure the mask is of type long for cross-entropy loss\n",
    "    \n",
    "        return image, mask\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
    "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
    "        return label_mapping\n",
    "        \n",
    "    def _map_mask(self, mask):\n",
    "        new_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)\n",
    "        for color, label_id in self.label_mapping.items():\n",
    "            color_mask = np.all(mask == color, axis=-1)\n",
    "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
    "        return new_mask\n",
    "\n",
    "# Define paths\n",
    "csv_file = 'gta5_segmentation_dataset.csv'\n",
    "\n",
    "# Define image transformations\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    A.RandomRotate90(),\n",
    "    A.RandomResizedCrop(height=512, width=1024, scale=(0.8, 1.0)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d574c1-75f8-4046-8653-1ed0ef6d3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val_Dataset size: 500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "        self.label_type = label_type\n",
    "\n",
    "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
    "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "\n",
    "        # Manually iterate over directories\n",
    "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
    "        for city in cities:\n",
    "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
    "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
    "\n",
    "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
    "                continue\n",
    "\n",
    "            for img_file in os.listdir(img_dir_city):\n",
    "                if img_file.endswith('_leftImg8bit.png'):\n",
    "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
    "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
    "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
    "\n",
    "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.label_paths.append(lbl_path)\n",
    "                    else:\n",
    "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        lbl_path = self.label_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = Image.open(lbl_path)\n",
    "\n",
    "        image = np.array(image)\n",
    "        label = np.array(label)\n",
    "        \n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=label)\n",
    "            image, label = augmented['image'], augmented['mask']\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_transforms = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_dataset = Cityscapes(root_dir='Cityscapes/Cityspaces', split='val', transforms=image_transforms)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(f\"Val_Dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafae0dd-8050-489b-a4b3-b1eb96ebef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_bisenet import BiSeNet\n",
    "from torch import nn\n",
    "\n",
    "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "context_path = 'resnet18'\n",
    "\n",
    "# Initialize the model\n",
    "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ccf9da-fad9-4c23-8e70-b74fc12afaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
    "        inputs_train = inputs_train.to(device)\n",
    "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
    "\n",
    "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
    "        outputs_train, cx1_sup, cx2_sup = model(inputs_train)  # Forward pass\n",
    "        # print(outputs_train.shape, targets_train.shape)\n",
    "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
    "        \n",
    "        aux_loss1 = loss_fn_train(cx1_sup, targets_train)\n",
    "        aux_loss2 = loss_fn_train(cx2_sup, targets_train)\n",
    "\n",
    "        loss = loss + aux_loss1 + aux_loss2\n",
    "        \n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer_train.step()  # Update the weights\n",
    "\n",
    "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
    "        _, predicted_train = outputs_train.max(1)\n",
    "        total += targets_train.size(0)\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = train_loss / total\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds[target_inds]).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    \n",
    "    return np.array(ious)\n",
    "\n",
    "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    all_ious = []  # List to store IoUs for each batch\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation during inference\n",
    "        for inputs_test, targets_test in dataloader:\n",
    "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_test = model(inputs_test)  # Forward pass\n",
    "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
    "\n",
    "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
    "            _, predicted_test = outputs_test.max(1)\n",
    "            total += targets_test.size(0)\n",
    "\n",
    "            # Compute IoU for this batch\n",
    "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
    "            all_ious.append(batch_ious)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = test_loss / total\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    all_ious = np.array(all_ious)\n",
    "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
    "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
    "    \n",
    "    return avg_loss, miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d545a-25f5-4e88-8d57-0c47141cd602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3065281097888946, mIoU: 11.56%\n",
      "Loss: 1.183289046049118, mIoU: 13.44%\n",
      "Loss: 1.749862690448761, mIoU: 10.87%\n",
      "Loss: 1.3642717125415802, mIoU: 12.32%\n",
      "Loss: 1.002148030757904, mIoU: 14.78%\n",
      "Loss: 0.9140036593675613, mIoU: 15.88%\n",
      "Loss: 1.1960161559581757, mIoU: 14.09%\n",
      "Loss: 1.3787701768875122, mIoU: 13.96%\n",
      "Loss: 1.4470102529525757, mIoU: 13.73%\n",
      "Loss: 1.3000136684179306, mIoU: 14.78%\n",
      "Loss: 1.5022656930685043, mIoU: 13.59%\n",
      "Loss: 1.2361995618343353, mIoU: 14.77%\n",
      "Loss: 1.0245310797691345, mIoU: 15.83%\n",
      "Loss: 0.9273065032958985, mIoU: 17.04%\n",
      "Loss: 1.2353467073440552, mIoU: 14.16%\n",
      "Loss: 1.3709070225954056, mIoU: 15.59%\n",
      "Loss: 1.0029244220256806, mIoU: 16.02%\n",
      "Loss: 1.2437726366519928, mIoU: 14.36%\n",
      "Loss: 1.307647983789444, mIoU: 13.18%\n",
      "Loss: 1.0403612014055252, mIoU: 16.15%\n",
      "Loss: 1.048096360206604, mIoU: 16.35%\n",
      "Loss: 0.832539591908455, mIoU: 18.70%\n",
      "Loss: 1.220076737523079, mIoU: 15.20%\n",
      "Loss: 0.8883176387548447, mIoU: 18.59%\n",
      "Loss: 1.1352757929563522, mIoU: 16.27%\n",
      "Loss: 1.6325649864673615, mIoU: 14.59%\n",
      "Loss: 0.9538957056999207, mIoU: 18.79%\n",
      "Loss: 1.1027721115350724, mIoU: 17.45%\n",
      "Loss: 0.9393797899484635, mIoU: 18.00%\n",
      "Loss: 2.1328849885463717, mIoU: 11.97%\n",
      "Loss: 0.950122915506363, mIoU: 18.55%\n",
      "Loss: 0.9587855044603347, mIoU: 18.55%\n",
      "Loss: 0.9142067255973816, mIoU: 18.68%\n",
      "Loss: 1.143675159215927, mIoU: 16.85%\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "for _ in range(50):\n",
    "    train(model, optimizer, train_dataloader, loss_fn)\n",
    "    avg_loss, miou = eval(model, val_dataloader, loss_fn, device=device)\n",
    "    print(f\"Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1411a9-ede3-4036-bc6a-50eb0cea390a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
