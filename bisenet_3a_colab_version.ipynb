{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcomag416/MLDL/blob/main/bisenet_3a_colab_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary code\n",
        "Feel free to delete/skip this part if run in a persistent environment"
      ],
      "metadata": {
        "id": "X2W7O-ywfU69"
      },
      "id": "X2W7O-ywfU69"
    },
    {
      "cell_type": "code",
      "source": [
        "#download bisenet model from official repository\n",
        "import sys\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "model_url = \"https://github.com/ooooverflow/BiSeNet/archive/refs/heads/master.zip\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(model_url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    #print(response.content)\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('./')\n",
        "    print('Download and extraction complete!')\n",
        "\n",
        "sys.path.insert(0, './BiSeNet-master')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pd-u3n_1gOy",
        "outputId": "9aeb47ea-6b8e-4e66-90fd-3e6f50b85b4a"
      },
      "id": "0Pd-u3n_1gOy",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download pytorchs1_gta from github\n",
        "\n",
        "url= \"https://github.com/marcomag416/MLDL/archive/refs/heads/main.zip\"\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(url)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    #print(response.content)\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('./')\n",
        "    print('Download and extraction complete!')\n",
        "\n",
        "sys.path.insert(0, './MLDL-main')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irlZ-v3zqFw6",
        "outputId": "4ebab438-af72-4f75-ad03-21553930b4e1"
      },
      "id": "irlZ-v3zqFw6",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download cityscapes dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with ZipFile(\"/content/drive/MyDrive/Colab Notebooks/dataset/Cityscapes.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./dataset\")\n",
        "\n",
        "cityscape_dataset_path = \"./dataset/Cityscapes/Cityspaces\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKBrbjoN4sOx",
        "outputId": "a87d450d-e927-4d51-c538-eddaf5c31626"
      },
      "id": "hKBrbjoN4sOx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download and index gta5 dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gta_path = \"/content/drive/MyDrive/Colab Notebooks/dataset/GTA5.zip\"\n",
        "\n",
        "gta_dataset_path = \"./dataset/\"\n",
        "\n",
        "#extract zip file\n",
        "with ZipFile(gta_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(gta_dataset_path)\n",
        "\n",
        "# Define paths\n",
        "images_path = gta_dataset_path + 'GTA5/images'\n",
        "labels_path = gta_dataset_path + 'GTA5/labels'\n",
        "\n",
        "# Initialize lists to hold data\n",
        "data = []\n",
        "\n",
        "# Load images and corresponding masks\n",
        "for image_filename in os.listdir(images_path):\n",
        "    if image_filename.endswith('.png'):\n",
        "        image_path = os.path.join(images_path, image_filename)\n",
        "        mask_path = os.path.join(labels_path, image_filename)\n",
        "\n",
        "        # Check if corresponding mask file exists\n",
        "        if os.path.exists(mask_path):\n",
        "            # Open image and mask to ensure they can be loaded (optional, for validation)\n",
        "            try:\n",
        "                image = Image.open(image_path)\n",
        "                mask = Image.open(mask_path)\n",
        "\n",
        "                # Add data to list\n",
        "                data.append({\n",
        "                    'image_path': image_path,\n",
        "                    'mask_path': mask_path\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {image_path} or {mask_path}: {e}\")\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('./gta5_segmentation_dataset.csv', index=False)\n",
        "\n",
        "print(\"Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW4Y5QFOnAW5",
        "outputId": "9186bd02-ab46-45a4-d82d-c25251894534"
      },
      "id": "fW4Y5QFOnAW5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic segmentation dataset created and saved as 'gta5_segmentation_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install and import wandb for data collecting\n",
        "!pip install wandb\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-Ci8W6afSF1",
        "outputId": "c69e7f77-1ea9-4697-e199-d5fca2d9a0dd"
      },
      "id": "7-Ci8W6afSF1",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.5.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarcomag416\u001b[0m (\u001b[33mmarco-magnanini\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2b BiseNet training and validation"
      ],
      "metadata": {
        "id": "4n2hNEvEfioO"
      },
      "id": "4n2hNEvEfioO"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from pytorchdl_gta5.labels import GTA5Labels_TaskCV2017\n",
        "\n",
        "if __name__ != '__main__':\n",
        "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Define the custom dataset class\n",
        "class GTASegmentationDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_mapping = self._create_label_mapping()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_name = self.data_frame.iloc[idx, 0]\n",
        "        mask_name = self.data_frame.iloc[idx, 1]\n",
        "\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        mask = Image.open(mask_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=np.array(image), mask=np.array(mask))\n",
        "            image, mask = augmented['image'], augmented['mask']\n",
        "\n",
        "        mask = self._map_mask(np.array(mask))\n",
        "\n",
        "        if self.transform:\n",
        "            # Convert mask to tensor without normalization\n",
        "            mask = torch.from_numpy(mask).permute(2, 0, 1).float()\n",
        "            mask = mask[0]\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def _create_label_mapping(self):\n",
        "        label_mapping = {label.color: label.ID for label in GTA5Labels_TaskCV2017.list_}\n",
        "        label_mapping[(0, 0, 0)] = 255  # Ensure unmapped colors go to 'unlabeled'\n",
        "        return label_mapping\n",
        "\n",
        "    def _map_mask(self, mask):\n",
        "        new_mask = np.zeros_like(mask)\n",
        "        for color, label_id in self.label_mapping.items():\n",
        "            color_mask = np.all(mask == color, axis=-1)\n",
        "            new_mask[color_mask] = label_id  # Use label_id instead of color\n",
        "        return new_mask\n",
        "\n",
        "\n",
        "\n",
        "# Define paths\n",
        "csv_file = './gta5_segmentation_dataset.csv'\n",
        "\n",
        "# Define image transformations\n",
        "transform = A.Compose([\n",
        "    A.Resize(720, 1280),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "train_dataset = GTASegmentationDataset(csv_file=csv_file, transform=transform)\n"
      ],
      "metadata": {
        "id": "M_wOtOxgoOcZ"
      },
      "id": "M_wOtOxgoOcZ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d9ff9f41-0185-4d9e-9a18-58439fef42bb",
      "metadata": {
        "id": "d9ff9f41-0185-4d9e-9a18-58439fef42bb",
        "outputId": "912d5673-5e61-413c-9d21-1c49ed3289d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val_Dataset size: 500\n"
          ]
        }
      ],
      "source": [
        "class Cityscapes(Dataset):\n",
        "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transforms = transforms\n",
        "        self.label_type = label_type\n",
        "\n",
        "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
        "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.label_paths = []\n",
        "\n",
        "        # Manually iterate over directories\n",
        "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
        "        for city in cities:\n",
        "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
        "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
        "\n",
        "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
        "                continue\n",
        "\n",
        "            for img_file in os.listdir(img_dir_city):\n",
        "                if img_file.endswith('_leftImg8bit.png'):\n",
        "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
        "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
        "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
        "\n",
        "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.label_paths.append(lbl_path)\n",
        "                    else:\n",
        "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        lbl_path = self.label_paths[idx]\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = Image.open(lbl_path)\n",
        "\n",
        "        image = np.array(image)\n",
        "        label = np.array(label)\n",
        "\n",
        "        if self.transforms:\n",
        "            augmented = self.transforms(image=image, mask=label)\n",
        "            image, label = augmented['image'], augmented['mask']\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Example usage\n",
        "image_transforms = A.Compose([\n",
        "    A.Resize(512, 1024),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_dataset = Cityscapes(root_dir=cityscape_dataset_path, split='val', transforms=image_transforms)\n",
        "\n",
        "\n",
        "print(f\"Val_Dataset size: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d0ed0f97-7f98-465d-9726-48c43989280f",
      "metadata": {
        "id": "d0ed0f97-7f98-465d-9726-48c43989280f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
        "    model.train()  # Set the model to training mode\n",
        "    train_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
        "        inputs_train = inputs_train.to(device)\n",
        "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
        "\n",
        "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
        "        outputs_train, _, _ = model(inputs_train)  # Forward pass\n",
        "        # print( \"train\")\n",
        "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
        "\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer_train.step()  # Update the weights\n",
        "\n",
        "        wandb.log({\"train/Batch loss\": loss})\n",
        "\n",
        "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
        "        _, predicted_train = outputs_train.max(1)\n",
        "        total += targets_train.size(0)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = train_loss / total\n",
        "\n",
        "    wandb.log({\"train/Epoch loss\": avg_loss})\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def compute_iou(pred, target, num_classes):\n",
        "    ious = []\n",
        "    pred = pred.view(-1)\n",
        "    target = target.view(-1)\n",
        "\n",
        "    for cls in range(num_classes):\n",
        "        pred_inds = (pred == cls)\n",
        "        target_inds = (target == cls)\n",
        "        intersection = (pred_inds[target_inds]).sum().item()\n",
        "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
        "        if union == 0:\n",
        "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
        "        else:\n",
        "            ious.append(intersection / union)\n",
        "\n",
        "    return np.array(ious)\n",
        "\n",
        "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0.0\n",
        "    total = 0\n",
        "    all_ious = []  # List to store IoUs for each batch\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during inference\n",
        "        for inputs_test, targets_test in dataloader:\n",
        "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_test = model(inputs_test)  # Forward pass\n",
        "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
        "\n",
        "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
        "            _, predicted_test = outputs_test.max(1)\n",
        "            total += targets_test.size(0)\n",
        "\n",
        "            # Compute IoU for this batch\n",
        "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
        "            all_ious.append(batch_ious)\n",
        "\n",
        "    # Calculate average loss\n",
        "    avg_loss = test_loss / total\n",
        "\n",
        "    wandb.log({})\n",
        "\n",
        "    # Calculate mean IoU\n",
        "    all_ious = np.array(all_ious)\n",
        "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
        "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
        "\n",
        "    wandb.log({\"val/Validation loss\": avg_loss, \"val/mIoU\": miou})\n",
        "\n",
        "    return avg_loss, miou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d68301fd-48a9-43f7-8749-f3ef6974be40",
      "metadata": {
        "id": "d68301fd-48a9-43f7-8749-f3ef6974be40"
      },
      "outputs": [],
      "source": [
        "from model.build_BiSeNet import BiSeNet\n",
        "from torch import nn\n",
        "from torch.optim.lr_scheduler import PolynomialLR\n",
        "\n",
        "\n",
        "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "\n",
        "context_path = 'resnet18'\n",
        "\n",
        "#save hyperparameters\n",
        "config = {\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"max_epochs\": 50,\n",
        "    \"batch_size\": 8,\n",
        "    \"weight_decay\": \"None\",\n",
        "    \"dataset\": \"Cityscapes\",\n",
        "    \"scheduler\": \"None\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"polyPower\": \"None\",\n",
        "    \"momentum\": \"None\"\n",
        "}\n",
        "\n",
        "\n",
        "# create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "# Initialize the model\n",
        "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "#scheduler = PolynomialLR(optimizer, total_iters=config[\"max_epochs\"], power=config[\"polyPower\"])\n",
        "scheduler = None\n",
        "\n",
        "# Set the manual seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3387c21-5c4e-4de8-9fe4-62c8fa5cac85",
      "metadata": {
        "id": "b3387c21-5c4e-4de8-9fe4-62c8fa5cac85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c79b1de7-42fa-4a94-a2fa-2517b7c519b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240607_132019-8up1jtt2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/marco-magnanini/bisenet_gta/runs/8up1jtt2' target=\"_blank\">no_tranforms</a></strong> to <a href='https://wandb.ai/marco-magnanini/bisenet_gta' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/marco-magnanini/bisenet_gta' target=\"_blank\">https://wandb.ai/marco-magnanini/bisenet_gta</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/marco-magnanini/bisenet_gta/runs/8up1jtt2' target=\"_blank\">https://wandb.ai/marco-magnanini/bisenet_gta/runs/8up1jtt2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.5753081026077271, mIoU: 10.10%\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "#run names\n",
        "project_name = \"bisenet_gta\"\n",
        "run_name = \"no_tranforms\"\n",
        "\n",
        "#start wandb run\n",
        "wandb.init(project=project_name, name=run_name, config=config)\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "# Setup training and save the results\n",
        "for epoch in range(config[\"max_epochs\"]):\n",
        "    wandb.log({\"Epoch\": epoch+1})\n",
        "    train(model, optimizer, train_dataloader, loss_fn)\n",
        "    avg_loss, miou = eval(model, val_dataloader, loss_fn, device=device)\n",
        "    if scheduler != None:\n",
        "      scheduler.step()\n",
        "    #save model state every 5 epochs\n",
        "    if(epoch % 5 == 0 and epoch!= 0):\n",
        "      torch.save(model.state_dict(), f\"./drive/MyDrive/Colab Notebooks/model_weights/{project_name}/{run_name}_epoch{epoch}.pth\")\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}