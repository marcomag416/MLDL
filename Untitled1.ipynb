{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ff9f41-0185-4d9e-9a18-58439fef42bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1572\n",
      "Val_Dataset size: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor idx, (im, lb) in enumerate(train_dataloader):\\n    print(f\"Batch {idx + 1}: Image batch shape: {im.shape}, Label batch shape: {lb.shape}\")\\n    \\n    unique_values, counts = np.unique(lb.numpy(), return_counts=True)\\n    print(\"Unique values in the label tensor:\", unique_values)\\n    print(\"Counts of unique values:\", counts)\\n    \\n    if idx >= 4:  # Print information for first 5 batches\\n        break\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "if __name__ != '__main__':\n",
    "    raise Exception(\"This script should not be imported; it should be run directly.\")\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Cityscapes(Dataset):\n",
    "    def __init__(self, root_dir, split, transforms=None, label_type='gtFine_labelTrainIds'):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "        self.label_type = label_type\n",
    "\n",
    "        self.images_dir = f\"{root_dir}/images/{split}\"\n",
    "        self.labels_dir = f\"{root_dir}/gtFine/{split}\"\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "\n",
    "        # Manually iterate over directories\n",
    "        cities = [city for city in os.listdir(self.images_dir) if os.path.isdir(f\"{self.images_dir}/{city}\")]\n",
    "        for city in cities:\n",
    "            img_dir_city = f\"{self.images_dir}/{city}\"\n",
    "            lbl_dir_city = f\"{self.labels_dir}/{city}\"\n",
    "\n",
    "            if not os.path.isdir(img_dir_city) or not os.path.isdir(lbl_dir_city):\n",
    "                continue\n",
    "\n",
    "            for img_file in os.listdir(img_dir_city):\n",
    "                if img_file.endswith('_leftImg8bit.png'):\n",
    "                    img_path = f\"{img_dir_city}/{img_file}\"\n",
    "                    lbl_file = img_file.replace('_leftImg8bit.png', f'_{self.label_type}.png')\n",
    "                    lbl_path = f\"{lbl_dir_city}/{lbl_file}\"\n",
    "\n",
    "                    if os.path.isfile(img_path) and os.path.isfile(lbl_path):\n",
    "                        self.image_paths.append(img_path)\n",
    "                        self.label_paths.append(lbl_path)\n",
    "                    else:\n",
    "                        print(f\"Warning: Image or label file not found for {img_file}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        lbl_path = self.label_paths[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = Image.open(lbl_path)\n",
    "\n",
    "        image = np.array(image)\n",
    "        label = np.array(label)\n",
    "        \n",
    "        if self.transforms:\n",
    "            augmented = self.transforms(image=image, mask=label)\n",
    "            image, label = augmented['image'], augmented['mask']\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_transforms = A.Compose([\n",
    "    A.Resize(512, 1024),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "dataset = Cityscapes(root_dir='Cityscapes/Cityspaces', split='train', transforms=image_transforms)\n",
    "val_dataset = Cityscapes(root_dir='Cityscapes/Cityspaces', split='val', transforms=image_transforms)\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Val_Dataset size: {len(val_dataset)}\")\n",
    "\"\"\"\n",
    "for idx, (im, lb) in enumerate(train_dataloader):\n",
    "    print(f\"Batch {idx + 1}: Image batch shape: {im.shape}, Label batch shape: {lb.shape}\")\n",
    "    \n",
    "    unique_values, counts = np.unique(lb.numpy(), return_counts=True)\n",
    "    print(\"Unique values in the label tensor:\", unique_values)\n",
    "    print(\"Counts of unique values:\", counts)\n",
    "    \n",
    "    if idx >= 4:  # Print information for first 5 batches\n",
    "        break\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68301fd-48a9-43f7-8749-f3ef6974be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_bisenet import BiSeNet\n",
    "from torch import nn\n",
    "\n",
    "# Set CUDA_LAUNCH_BLOCKING environment variable\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "\n",
    "context_path = 'resnet18'\n",
    "\n",
    "# Initialize the model\n",
    "model = BiSeNet(num_classes=19, context_path=context_path).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=255)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0ed0f97-7f98-465d-9726-48c43989280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, optimizer_train, dataloader, loss_fn_train):\n",
    "    model.train()  # Set the model to training mode\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    for idx, (inputs_train, targets_train) in enumerate(dataloader):\n",
    "        inputs_train = inputs_train.to(device)\n",
    "        targets_train = targets_train.to(device, dtype=torch.long)  # Move data to the appropriate device\n",
    "\n",
    "        optimizer_train.zero_grad()  # Zero out gradients from the previous iteration\n",
    "        outputs_train, _, _ = model(inputs_train)  # Forward pass\n",
    "        # print( \"train\")\n",
    "        loss = loss_fn_train(outputs_train, targets_train)  # Calculate the loss\n",
    "        \n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer_train.step()  # Update the weights\n",
    "\n",
    "        train_loss += loss.item() * inputs_train.size(0)  # Accumulate the total loss\n",
    "        _, predicted_train = outputs_train.max(1)\n",
    "        total += targets_train.size(0)\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = train_loss / total\n",
    "    \n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def compute_iou(pred, target, num_classes):\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred == cls)\n",
    "        target_inds = (target == cls)\n",
    "        intersection = (pred_inds[target_inds]).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # If there is no union, set IoU to NaN\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    \n",
    "    return np.array(ious)\n",
    "\n",
    "def eval(model, dataloader, loss_fn, device, num_classes=19):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    all_ious = []  # List to store IoUs for each batch\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation during inference\n",
    "        for inputs_test, targets_test in dataloader:\n",
    "            inputs_test, targets_test = inputs_test.to(device), targets_test.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs_test = model(inputs_test)  # Forward pass\n",
    "            loss = loss_fn(outputs_test, targets_test)  # Calculate the loss\n",
    "\n",
    "            test_loss += loss.item() * inputs_test.size(0)  # Accumulate the total loss\n",
    "            _, predicted_test = outputs_test.max(1)\n",
    "            total += targets_test.size(0)\n",
    "\n",
    "            # Compute IoU for this batch\n",
    "            batch_ious = compute_iou(predicted_test, targets_test, num_classes)\n",
    "            all_ious.append(batch_ious)\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = test_loss / total\n",
    "    \n",
    "    # Calculate mean IoU\n",
    "    all_ious = np.array(all_ious)\n",
    "    mean_iou = np.nanmean(all_ious, axis=0)  # Mean IoU for each class\n",
    "    miou = np.nanmean(mean_iou)  # Mean IoU across all classes\n",
    "    \n",
    "    return avg_loss, miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3387c21-5c4e-4de8-9fe4-62c8fa5cac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5755923016071319, mIoU: 22.67%\n",
      "Loss: 0.3735559182167053, mIoU: 29.31%\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Setup training and save the results\n",
    "for _ in range(50):\n",
    "    train(model, optimizer, train_dataloader, loss_fn)\n",
    "    avg_loss, miou = eval(model, val_dataloader, loss_fn, device=device)\n",
    "    print(f\"Loss: {avg_loss}, mIoU: {miou*100:.2f}%\")\n",
    "\n",
    "# End the timer and print out how long it took\n",
    "end_time = timer()\n",
    "print(f\"[INFO] Total training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44709e8-c3f0-462e-bc25-eb0d9fffdaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
